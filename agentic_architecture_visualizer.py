# -*- coding: utf-8 -*-
"""
Agentic Architecture å¯è§†åŒ–ç³»ç»Ÿ

ä½¿ç”¨Streamlitæ„å»ºçš„äº¤äº’å¼ç•Œé¢ï¼Œç”¨äºå±•ç¤ºå’Œä½¿ç”¨å…¨éƒ¨ 17 ç§ Agentic Architecture ç¤ºä¾‹ã€‚

åŠŸèƒ½ç‰¹ç‚¹ï¼š
- æ”¯æŒ 01â€“17 å…± 17 ç§æ™ºèƒ½ä½“æ¶æ„çš„å¯è§†åŒ–å±•ç¤º
- ç›´è§‚çš„æ¶æ„é€‰æ‹©ç•Œé¢
- å®æ—¶æ˜¾ç¤ºåˆ†æè¿‡ç¨‹å’Œæ—¥å¿—
- ç¾è§‚çš„ç»“æœå±•ç¤º
- å¤šæ™ºèƒ½ä½“ä¸å•æ™ºèƒ½ä½“ç³»ç»Ÿå¯¹æ¯”
- æ”¯æŒè‡ªå®šä¹‰å‚æ•°é…ç½®

è¿è¡Œæ–¹å¼ï¼š
```bash
streamlit run agentic_architecture_visualizer.py
```
"""

import os
import time
import streamlit as st
from dotenv import load_dotenv
from rich.console import Console

# å¯¼å…¥å¿…è¦çš„åº“ç”¨äºåŠ¨æ€åŠ è½½æ¨¡å—
import importlib.util
import sys

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# åˆå§‹åŒ–æ§åˆ¶å°
console = Console()

# è®¾ç½®é¡µé¢æ ‡é¢˜å’Œå¸ƒå±€
st.set_page_config(
    page_title="Agentic Architecture å¯è§†åŒ–ç³»ç»Ÿ",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .stButton > button {
        width: 100%;
        margin-bottom: 10px;
    }
    .analysis-section {
        background-color: #f5f5f5;
        padding: 15px;
        border-radius: 10px;
        margin-bottom: 20px;
    }
    .agent-title {
        color: #4CAF50;
        font-weight: bold;
        margin-bottom: 10px;
    }
    .monolithic-title {
        color: #FF9800;
        font-weight: bold;
        margin-bottom: 10px;
    }
    .final-report {
        background-color: #e8f5e9;
        padding: 20px;
        border-radius: 10px;
        border-left: 5px solid #4CAF50;
    }
    .log-section {
        background-color: #2c3e50;
        color: #ecf0f1;
        padding: 15px;
        border-radius: 5px;
        font-family: monospace;
        font-size: 14px;
        white-space: pre-wrap;
        margin-bottom: 15px;
    }
</style>
""", unsafe_allow_html=True)

# ä¾§è¾¹æ 
st.sidebar.title("ğŸ¤– Agentic Architecture å¯è§†åŒ–ç³»ç»Ÿ")
st.sidebar.markdown("---")

# é€‰æ‹©æ¶æ„ç¤ºä¾‹
st.sidebar.subheader("é€‰æ‹©æ¶æ„ç¤ºä¾‹")
architecture_choices = [
    "01 - åæ€å‹æ™ºèƒ½ä½“ (Reflection)",
    "02 - å·¥å…·ä½¿ç”¨æ™ºèƒ½ä½“ (Tool Use)",
    "03 - ååº”å‹æ™ºèƒ½ä½“ (ReAct)",
    "04 - è§„åˆ’å‹æ™ºèƒ½ä½“ (Planning)",
    "05 - å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ (Multi-Agent)",
    "06 - è§„åˆ’â†’æ‰§è¡Œâ†’éªŒè¯æ™ºèƒ½ä½“ (Plannerâ†’Executorâ†’Verifier)",
    "07 - é»‘æ¿ç³»ç»Ÿ (Blackboard System)",
    "08 - æƒ…æ™¯è®°å¿†+è¯­ä¹‰è®°å¿†æ ˆ (Episodic+Semantic Memory Stack)",
    "09 - æ€ç»´æ ‘æ™ºèƒ½ä½“ (Tree-of-Thoughts)",
    "10 - æ€ç»´æ¨¡å‹å¾ªç¯æ™ºèƒ½ä½“ (Mental-Model-in-the-Loop)",
    "11 - å…ƒæ§åˆ¶å™¨æ™ºèƒ½ä½“ (Meta-Controller)",
    "12 - å›¾/ä¸–ç•Œæ¨¡å‹è®°å¿† (Graph)",
    "13 - å¹¶è¡Œæ¢ç´¢+é›†æˆå†³ç­– (Ensemble)",
    "14 - å¯è§‚æµ‹ä¸è¯•è·‘å¤–å£³ (Dry-Run Harness)",
    "15 - è‡ªæ”¹è¿›å¾ªç¯ (Self-Refine / RLHF)",
    "16 - ç»†èƒè‡ªåŠ¨æœº/ç½‘æ ¼æ™ºèƒ½ä½“ (Cellular Automata)",
    "17 - åæ€å¼å…ƒè®¤çŸ¥ (Reflexive Metacognitive)",
]
selected_architecture = st.sidebar.selectbox("", architecture_choices)

# æ¨¡å‹é€‰æ‹©
st.sidebar.subheader("é€‰æ‹©æ¨¡å‹")
model_choices = {
    "DeepSeek-V3.2": "deepseek-ai/DeepSeek-V3.2",
    "DeepSeek-R1-0528": "deepseek-ai/DeepSeek-R1-0528"
}
selected_model = st.sidebar.selectbox("", list(model_choices.keys()))
# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ["MODELSCOPE_MODEL_ID"] = model_choices[selected_model]

# APIå¯†é’¥æ£€æŸ¥
api_key = os.environ.get("MODELSCOPE_API_KEY")
if not api_key:
    st.sidebar.error("æœªæ‰¾åˆ°MODELSCOPE_API_KEYç¯å¢ƒå˜é‡")
    st.sidebar.info("è¯·åˆ›å»º.envæ–‡ä»¶å¹¶è®¾ç½®APIå¯†é’¥")
    api_key_input = st.sidebar.text_input("æˆ–ç›´æ¥è¾“å…¥APIå¯†é’¥", type="password")
    if api_key_input:
        os.environ["MODELSCOPE_API_KEY"] = api_key_input

# ä¸»ç•Œé¢
st.title("ğŸ“Š Agentic Architecture å¯è§†åŒ–ç³»ç»Ÿ")

# å®šä¹‰å„ä¸ªæ¶æ„çš„å¯è§†åŒ–å‡½æ•°
def visualize_reflection():
    """å¯è§†åŒ–åæ€å‹æ™ºèƒ½ä½“"""
    st.markdown("### 01 - åæ€å‹æ™ºèƒ½ä½“ (Reflection)")
    
    # åŠ è½½01_reflectionæ¨¡å—
    spec = importlib.util.spec_from_file_location("reflection", "01_reflection.py")
    reflection = importlib.util.module_from_spec(spec)
    sys.modules["reflection"] = reflection
    spec.loader.exec_module(reflection)
    
    # ä»æ¨¡å—ä¸­å¯¼å…¥æ‰€éœ€å‡½æ•°å’Œç±»
    init_llm = reflection.init_llm
    build_app = reflection.build_app
    run_workflow = reflection.run_workflow
    print_before_after = reflection.print_before_after
    
    # ç”¨æˆ·è¾“å…¥åŒºåŸŸ
    default_request = "Write a Python function to find the nth Fibonacci number."
    user_request = st.text_area("è¾“å…¥æ‚¨çš„è¯·æ±‚", value=default_request, height=100)
    
    # æ‰§è¡ŒæŒ‰é’®
    if st.button("å¼€å§‹æ‰§è¡Œåæ€å·¥ä½œæµ"):
        # æ£€æŸ¥APIå¯†é’¥
        if not os.environ.get("MODELSCOPE_API_KEY"):
            st.error("è¯·å…ˆè®¾ç½®APIå¯†é’¥")
        else:
            with st.spinner("æ­£åœ¨åˆå§‹åŒ–ç³»ç»Ÿ..."):
                # åˆå§‹åŒ–LLM
                llm = init_llm()
                
                # æ„å»ºå·¥ä½œæµ
                app = build_app(llm)
            
            st.success("ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼")
            
            # åˆ›å»ºæ—¥å¿—æ˜¾ç¤ºåŒºåŸŸ
            logs_container = st.empty()
            log_content = ""
            
            # é‡å®šå‘æ§åˆ¶å°è¾“å‡ºåˆ°æ—¥å¿—åŒºåŸŸ
            import io
            from contextlib import redirect_stdout
            
            f = io.StringIO()
            with redirect_stdout(f):
                # æ‰§è¡Œå·¥ä½œæµ
                final_state = run_workflow(app, user_request)
                
            # è·å–æ§åˆ¶å°è¾“å‡º
            log_content = f.getvalue()
            
            # æ˜¾ç¤ºæ—¥å¿—
            st.markdown("### æ‰§è¡Œæ—¥å¿—")
            st.text_area("", value=log_content, height=300, disabled=True)
            
            # æ˜¾ç¤ºç»“æœ
            st.markdown("### æ‰§è¡Œç»“æœ")
            
            # æ˜¾ç¤ºåˆç¨¿
            if "draft" in final_state:
                st.markdown("#### 1. åˆç¨¿")
                explanation = final_state["draft"].get("explanation", "")
                if explanation:
                    st.markdown(f"**è¯´æ˜**ï¼š{explanation}")
                code = final_state["draft"].get("code", "")
                if code:
                    st.code(code, language="python")
            
            # æ˜¾ç¤ºè¯„å®¡ç»“æœ
            if "critique" in final_state:
                st.markdown("#### 2. è¯„å®¡")
                critique = final_state["critique"]
                st.json(critique)
            
            # æ˜¾ç¤ºæ”¹å†™åçš„ä»£ç 
            if "refined_code" in final_state:
                st.markdown("#### 3. æ”¹å†™å")
                refined_code = final_state["refined_code"].get("refined_code", "")
                if refined_code:
                    st.code(refined_code, language="python")
                refinement_summary = final_state["refined_code"].get("refinement_summary", "")
                if refinement_summary:
                    st.markdown(f"**æ”¹è¿›è¯´æ˜**ï¼š{refinement_summary}")


def visualize_tool_use():
    """å¯è§†åŒ–å·¥å…·ä½¿ç”¨æ™ºèƒ½ä½“"""
    st.markdown("### 02 - å·¥å…·ä½¿ç”¨æ™ºèƒ½ä½“ (Tool Use)")
    
    # åŠ è½½02_tool_useæ¨¡å—
    spec = importlib.util.spec_from_file_location("tool_use", "02_tool_use.py")
    tool_use = importlib.util.module_from_spec(spec)
    sys.modules["tool_use"] = tool_use
    spec.loader.exec_module(tool_use)
    
    # ä»æ¨¡å—ä¸­å¯¼å…¥æ‰€éœ€å‡½æ•°å’Œç±»
    init_llm = tool_use.init_llm
    build_app = tool_use.build_app
    run_workflow = tool_use.run_workflow
    
    # ç”¨æˆ·è¾“å…¥åŒºåŸŸ
    default_request = "è¯·å¯¹è¿™æ®µè¯åšç®€å•æ–‡æœ¬ç®¡çº¿ï¼š'LangGraph makes it easier to build stateful AI workflows.' æ ‡å‡†åŒ–ã€åˆ†è¯ã€æå–5ä¸ªå…³é”®è¯ï¼Œæœ€åç»“åˆå½“å‰æ—¶é—´æ¸²æŸ“ä¸º Markdown æŠ¥å‘Šã€‚"
    user_request = st.text_area("è¾“å…¥æ‚¨çš„è¯·æ±‚", value=default_request, height=100)
    
    # æ‰§è¡ŒæŒ‰é’®
    if st.button("å¼€å§‹æ‰§è¡Œå·¥å…·ä½¿ç”¨å·¥ä½œæµ"):
        # æ£€æŸ¥APIå¯†é’¥
        if not os.environ.get("MODELSCOPE_API_KEY"):
            st.error("è¯·å…ˆè®¾ç½®APIå¯†é’¥")
        else:
            with st.spinner("æ­£åœ¨åˆå§‹åŒ–ç³»ç»Ÿ..."):
                # åˆå§‹åŒ–LLM
                llm = init_llm()
                
                # æ„å»ºå·¥ä½œæµ
                app = build_app(llm)
            
            st.success("ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼")
            
            # åˆ›å»ºæ—¥å¿—æ˜¾ç¤ºåŒºåŸŸ
            logs_container = st.empty()
            log_content = ""
            
            # é‡å®šå‘æ§åˆ¶å°è¾“å‡ºåˆ°æ—¥å¿—åŒºåŸŸ
            import io
            from contextlib import redirect_stdout
            
            f = io.StringIO()
            with redirect_stdout(f):
                # æ‰§è¡Œå·¥ä½œæµ
                final_state = run_workflow(app, user_request)
            
            # è·å–æ§åˆ¶å°è¾“å‡º
            log_content = f.getvalue()
            
            # æ˜¾ç¤ºæ—¥å¿—
            st.markdown("### æ‰§è¡Œæ—¥å¿—")
            st.text_area("", value=log_content, height=300, disabled=True)
            
            # æ˜¾ç¤ºç»“æœ
            st.markdown("### æ‰§è¡Œç»“æœ")
            
            # æ˜¾ç¤ºå·¥å…·è®¡åˆ’
            if "tool_plan" in final_state:
                st.markdown("#### 1. å·¥å…·è®¡åˆ’")
                plan_summary = final_state["tool_plan"].get("plan_summary", "")
                if plan_summary:
                    st.markdown(f"**è®¡åˆ’æ‘˜è¦**ï¼š{plan_summary}")
                planned_calls = final_state["tool_plan"].get("planned_calls", [])
                if planned_calls:
                    for i, call in enumerate(planned_calls):
                        st.markdown(f"**æ­¥éª¤ {i+1}**ï¼š{call.get('tool_name')}")
                        st.markdown(f"- ç†ç”±ï¼š{call.get('reason')}")
                        st.markdown(f"- å‚æ•°ï¼š{call.get('arguments')}")
                        if call.get('assign_to'):
                            st.markdown(f"- ç»“æœä¿å­˜åˆ°ï¼š{call.get('assign_to')}")
                        st.markdown("")
            
            # æ˜¾ç¤ºå·¥å…·æ‰§è¡Œç»“æœ
            if "tool_results" in final_state:
                st.markdown("#### 2. æ‰§è¡Œç»“æœ")
                execution_summary = final_state["tool_results"].get("execution_summary", "")
                if execution_summary:
                    st.markdown(f"**æ‰§è¡Œæ‘˜è¦**ï¼š{execution_summary}")
                results = final_state["tool_results"].get("results", [])
                if results:
                    for result in results:
                        st.markdown(f"**å·¥å…·**ï¼š{result.get('tool_name')}")
                        st.markdown(f"**è¾“å‡º**ï¼š{result.get('output')}")
                        st.markdown("")
            
            # æ˜¾ç¤ºæœ€ç»ˆå›ç­”
            if "final_answer" in final_state:
                st.markdown("#### 3. æœ€ç»ˆå›ç­”")
                answer = final_state["final_answer"].get("answer", "")
                if answer:
                    st.markdown(answer)
                sources = final_state["final_answer"].get("sources", [])
                if sources:
                    st.markdown(f"**æ¥æº**ï¼š{sources}")


def visualize_react():
    """å¯è§†åŒ–ååº”å‹æ™ºèƒ½ä½“"""
    st.markdown("### 03 - ååº”å‹æ™ºèƒ½ä½“ (ReAct)")
    
    # åŠ è½½03_reactæ¨¡å—
    spec = importlib.util.spec_from_file_location("react", "03_react.py")
    react = importlib.util.module_from_spec(spec)
    sys.modules["react"] = react
    spec.loader.exec_module(react)
    
    # ä»æ¨¡å—ä¸­å¯¼å…¥æ‰€éœ€å‡½æ•°å’Œç±»
    init_llm = react.init_llm
    build_app = react.build_app
    run_workflow = react.run_workflow
    
    # ç”¨æˆ·è¾“å…¥åŒºåŸŸ
    default_request = "è¯·è®¡ç®—è¡¨è¾¾å¼ 12*(3+4)ï¼Œå¹¶ç”¨ä¸€å¥è¯è¯´æ˜ç»“æœã€‚"
    user_request = st.text_area("è¾“å…¥æ‚¨çš„é—®é¢˜", value=default_request, height=100)
    
    # æ‰§è¡ŒæŒ‰é’®
    if st.button("å¼€å§‹æ‰§è¡ŒReActå·¥ä½œæµ"):
        # æ£€æŸ¥APIå¯†é’¥
        if not os.environ.get("MODELSCOPE_API_KEY"):
            st.error("è¯·å…ˆè®¾ç½®APIå¯†é’¥")
        else:
            with st.spinner("æ­£åœ¨åˆå§‹åŒ–ç³»ç»Ÿ..."):
                # åˆå§‹åŒ–LLM
                llm = init_llm()
                
                # æ„å»ºå·¥ä½œæµ
                app = build_app(llm)
            
            st.success("ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼")
            
            # åˆ›å»ºæ—¥å¿—æ˜¾ç¤ºåŒºåŸŸ
            logs_container = st.empty()
            log_content = ""
            
            # é‡å®šå‘æ§åˆ¶å°è¾“å‡ºåˆ°æ—¥å¿—åŒºåŸŸ
            import io
            from contextlib import redirect_stdout
            
            f = io.StringIO()
            with redirect_stdout(f):
                # æ‰§è¡Œå·¥ä½œæµ
                final_state = run_workflow(app, user_request)
            
            # è·å–æ§åˆ¶å°è¾“å‡º
            log_content = f.getvalue()
            
            # æ˜¾ç¤ºæ—¥å¿—
            st.markdown("### æ‰§è¡Œæ—¥å¿—")
            st.text_area("", value=log_content, height=300, disabled=True)
            
            # æ˜¾ç¤ºç»“æœ
            st.markdown("### æ‰§è¡Œç»“æœ")
            
            # æ˜¾ç¤ºæ­¥éª¤
            if "steps" in final_state:
                st.markdown("#### 1. ReAct æ­¥éª¤")
                steps = final_state["steps"]
                for i, step in enumerate(steps):
                    st.markdown(f"**æ­¥éª¤ {i+1}**")
                    if step.get("thought"):
                        st.markdown(f"- æ€è€ƒï¼š{step.get('thought')}")
                    if step.get("action"):
                        st.markdown(f"- è¡ŒåŠ¨ï¼š{step.get('action')}")
                        if step.get("action_input"):
                            st.markdown(f"- è¾“å…¥ï¼š{step.get('action_input')}")
                    if step.get("observation"):
                        st.markdown(f"- è§‚å¯Ÿï¼š{step.get('observation')}")
                    st.markdown("")
            
            # æ˜¾ç¤ºæœ€ç»ˆå›ç­”
            if "final_answer" in final_state:
                st.markdown("#### 2. æœ€ç»ˆå›ç­”")
                st.markdown(final_state["final_answer"])
            elif "steps" in final_state and steps and steps[-1].get("final_answer"):
                st.markdown("#### 2. æœ€ç»ˆå›ç­”")
                st.markdown(steps[-1].get("final_answer"))


def visualize_planning():
    """å¯è§†åŒ–è§„åˆ’å‹æ™ºèƒ½ä½“"""
    st.markdown("### 04 - è§„åˆ’å‹æ™ºèƒ½ä½“ (Planning)")
    
    # åŠ è½½04_planning.pyæ¨¡å—
    spec = importlib.util.spec_from_file_location("planning", "04_planning.py")
    planning = importlib.util.module_from_spec(spec)
    sys.modules["planning"] = planning
    spec.loader.exec_module(planning)
    
    # ä»æ¨¡å—ä¸­å¯¼å…¥æ‰€éœ€å‡½æ•°å’Œç±»
    init_llm = planning.init_llm
    web_search = planning.web_search
    ModelScopeChatWithTools = planning.ModelScopeChatWithTools
    react_agent_app = planning.react_agent_app
    planning_agent_app = planning.planning_agent_app
    
    # ç”¨æˆ·è¾“å…¥åŒºåŸŸ
    default_request = "æŸ¥æ‰¾åŒ—äº¬ã€ä¸Šæµ·å’Œå¹¿å·çš„äººå£ã€‚ç„¶åè®¡ç®—å®ƒä»¬çš„æ€»äººå£ã€‚æœ€åï¼Œå°†æ€»äººå£ä¸ä¸­å›½äººå£è¿›è¡Œæ¯”è¾ƒï¼Œå¹¶è¯´æ˜å“ªä¸ªæ›´å¤§ã€‚"
    user_request = st.text_area("è¾“å…¥æ‚¨çš„è¯·æ±‚", value=default_request, height=100)
    
    # æ‰§è¡ŒæŒ‰é’®
    if st.button("å¼€å§‹æ‰§è¡Œè§„åˆ’å·¥ä½œæµ"):
        # æ£€æŸ¥APIå¯†é’¥
        if not os.environ.get("MODELSCOPE_API_KEY"):
            st.error("è¯·å…ˆè®¾ç½®APIå¯†é’¥")
        else:
            # åˆ›å»ºæ—¥å¿—æ˜¾ç¤ºåŒºåŸŸ
            logs_container = st.empty()
            log_content = ""
            
            # é‡å®šå‘æ§åˆ¶å°è¾“å‡ºåˆ°æ—¥å¿—åŒºåŸŸ
            import io
            from contextlib import redirect_stdout
            from langchain_core.messages import HumanMessage
            
            f = io.StringIO()
            with redirect_stdout(f):
                # æ‰§è¡Œå·¥ä½œæµ
                planning_result = planning_agent_app.invoke({
                    "messages": [
                        HumanMessage(content=user_request)
                    ]
                })
            
            # è·å–æ§åˆ¶å°è¾“å‡º
            log_content = f.getvalue()
            
            # æ˜¾ç¤ºæ—¥å¿—
            st.markdown("### æ‰§è¡Œæ—¥å¿—")
            st.text_area("", value=log_content, height=300, disabled=True)
            
            # æ˜¾ç¤ºç»“æœ
            st.markdown("### æ‰§è¡Œç»“æœ")
            
            # æ˜¾ç¤ºè§„åˆ’è¿‡ç¨‹
            messages = planning_result["messages"]
            if messages:
                # æ˜¾ç¤ºç”Ÿæˆçš„è®¡åˆ’
                for i, msg in enumerate(messages):
                    if i == 1 and hasattr(msg, 'content') and "1. " in msg.content and "2. " in msg.content:
                        st.markdown("#### 1. ç”Ÿæˆçš„è®¡åˆ’")
                        st.markdown(msg.content)
                        break
                
                # æ˜¾ç¤ºæ‰§è¡Œç»“æœå’Œæœ€ç»ˆç­”æ¡ˆ
                for i, msg in reversed(list(enumerate(messages))):
                    if hasattr(msg, 'content') and msg.content:
                        if "æ‰§è¡Œå®Œæˆ" in msg.content:
                            st.markdown("#### 2. æ‰§è¡Œç»“æœ")
                            st.markdown(msg.content.replace("æ‰§è¡Œå®Œæˆã€‚ç»“æœï¼š\n", ""))
                        elif (i == len(messages) - 1) or "æœ€ç»ˆç­”æ¡ˆ" in msg.content:
                            st.markdown("#### 3. æœ€ç»ˆç­”æ¡ˆ")
                            st.markdown(msg.content)
                            break


def visualize_multi_agent():
    """å¯è§†åŒ–å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ"""
    # åŠ è½½05_multi_agentæ¨¡å—
    spec = importlib.util.spec_from_file_location("multi_agent", "05_multi_agent.py")
    multi_agent = importlib.util.module_from_spec(spec)
    sys.modules["multi_agent"] = multi_agent
    spec.loader.exec_module(multi_agent)
    
    # ä»åŠ¨æ€åŠ è½½çš„æ¨¡å—ä¸­å¯¼å…¥æ‰€éœ€å‡½æ•°å’Œå˜é‡
    init_llm = multi_agent.init_llm
    web_search = multi_agent.web_search
    ModelScopeChatWithTools = multi_agent.ModelScopeChatWithTools
    build_monolithic_agent = multi_agent.build_monolithic_agent
    build_multi_agent_system = multi_agent.build_multi_agent_system
    GLOBAL_LOGS = multi_agent.GLOBAL_LOGS
    from langchain_core.messages import SystemMessage, HumanMessage
    
    st.markdown("### 05 - å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ (Multi-Agent)")
    
    # å…¬å¸é€‰æ‹©
    companies = [
        "NVIDIA (NVDA)",
        "é˜¿é‡Œå·´å·´ (BABA)",
        "è‹¹æœ (AAPL)",
        "å¾®è½¯ (MSFT)",
        "ç‰¹æ–¯æ‹‰ (TSLA)",
        "äºšé©¬é€Š (AMZN)"
    ]
    selected_company = st.selectbox("é€‰æ‹©åˆ†æå…¬å¸", companies)
    
    # è‡ªå®šä¹‰å…¬å¸é€‰é¡¹
    custom_company = st.text_input("æˆ–è¾“å…¥è‡ªå®šä¹‰å…¬å¸", "")
    if custom_company:
        selected_company = custom_company
    
    # ç³»ç»Ÿé€‰æ‹©
    analysis_type = st.radio(
        "é€‰æ‹©åˆ†æç³»ç»Ÿ",
        ["å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ", "å•æ™ºèƒ½ä½“ç³»ç»Ÿ", "å¯¹æ¯”åˆ†æ"]
    )
    
    # åˆ†ææŒ‰é’®
    if st.button("å¼€å§‹åˆ†æ"):
        # æ£€æŸ¥APIå¯†é’¥
        if not os.environ.get("MODELSCOPE_API_KEY"):
            st.error("è¯·å…ˆè®¾ç½®APIå¯†é’¥")
        else:
            with st.spinner("æ­£åœ¨åˆå§‹åŒ–ç³»ç»Ÿ..."):
                # åˆå§‹åŒ–LLMå’Œå·¥å…·
                llm = init_llm()
                llm_with_tools = ModelScopeChatWithTools(llm, [web_search])
                
                # æ„å»ºå•æ™ºèƒ½ä½“ç³»ç»Ÿ
                monolithic_agent = build_monolithic_agent(llm_with_tools)
                
                # æ„å»ºå¤šæ™ºèƒ½ä½“ç³»ç»Ÿ
                multi_agent_system = build_multi_agent_system()
            
            st.success("ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼")
            
            # å®šä¹‰åˆ†ææŸ¥è¯¢
            analysis_query = f"ä¸º{selected_company}åˆ›å»ºä¸€ä»½ç®€è¦ä½†å…¨é¢çš„å¸‚åœºåˆ†ææŠ¥å‘Šã€‚æŠ¥å‘Šåº”åŒ…æ‹¬ä¸‰ä¸ªéƒ¨åˆ†ï¼š1. æœ€è¿‘æ–°é—»å’Œå¸‚åœºæƒ…ç»ªæ‘˜è¦ã€‚2. è‚¡ç¥¨ä»·æ ¼è¶‹åŠ¿çš„åŸºæœ¬æŠ€æœ¯åˆ†æã€‚3. å…¬å¸æœ€è¿‘è´¢åŠ¡è¡¨ç°çš„åˆ†æã€‚"
            
            # æ˜¾ç¤ºæŸ¥è¯¢å†…å®¹
            st.markdown(f"#### åˆ†æä»»åŠ¡ï¼š")
            st.info(analysis_query)
            
            # æ‰§è¡Œåˆ†æ
            if analysis_type in ["å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ", "å¯¹æ¯”åˆ†æ"]:
                st.markdown("## ğŸ¯ å¤šæ™ºèƒ½ä½“ç³»ç»Ÿåˆ†æç»“æœ")
                
                # æ¸…ç©ºä¹‹å‰çš„æ—¥å¿—
                GLOBAL_LOGS.clear()
                
                # åˆ›å»ºæ—¥å¿—æ˜¾ç¤ºåŒºåŸŸ
                logs_container = st.empty()
                log_content = ""
                
                # æ‰§è¡Œå¤šæ™ºèƒ½ä½“ç³»ç»Ÿåˆ†æ
                final_multi_output = multi_agent_system.invoke({
                    "messages": [
                        HumanMessage(content=analysis_query)
                    ]
                })
                
                # æ˜¾ç¤ºæ‰€æœ‰æ—¥å¿—
                for log in GLOBAL_LOGS:
                    log_content += f"{log}<br>"
                logs_container.markdown(f"### æ‰§è¡Œæ—¥å¿—<br><div class='log-section'>{log_content}</div>", unsafe_allow_html=True)
                
                # å±•ç¤ºå¤šæ™ºèƒ½ä½“åˆ†æç»“æœ
                messages = final_multi_output['messages']
                
                for msg in messages:
                    if hasattr(msg, 'content') and msg.content:
                        if "## æ–°é—»ä¸å¸‚åœºæƒ…ç»ªåˆ†æ" in msg.content:
                            st.markdown("### ğŸ“° æ–°é—»ä¸å¸‚åœºæƒ…ç»ªåˆ†æ")
                            st.markdown(msg.content.replace("## æ–°é—»ä¸å¸‚åœºæƒ…ç»ªåˆ†æ", ""))
                        elif "## æŠ€æœ¯åˆ†æ" in msg.content:
                            st.markdown("### ğŸ“ˆ æŠ€æœ¯åˆ†æ")
                            st.markdown(msg.content.replace("## æŠ€æœ¯åˆ†æ", ""))
                        elif "## è´¢åŠ¡åˆ†æ" in msg.content:
                            st.markdown("### ğŸ’° è´¢åŠ¡åˆ†æ")
                            st.markdown(msg.content.replace("## è´¢åŠ¡åˆ†æ", ""))
                        else:
                            st.markdown("### ğŸ“‹ æœ€ç»ˆç»¼åˆæŠ¥å‘Š")
                            st.markdown(msg.content)
                
                # ä¿å­˜å¤šæ™ºèƒ½ä½“ç»“æœç”¨äºå¯¹æ¯”
                multi_agent_result = messages[-1].content if messages else ""
            
            if analysis_type in ["å•æ™ºèƒ½ä½“ç³»ç»Ÿ", "å¯¹æ¯”åˆ†æ"]:
                # æ·»åŠ åˆ†éš”çº¿
                if analysis_type == "å¯¹æ¯”åˆ†æ":
                    st.markdown("---")
                
                st.markdown("## ğŸ¯ å•æ™ºèƒ½ä½“ç³»ç»Ÿåˆ†æç»“æœ")
                
                # æ‰§è¡Œå•æ™ºèƒ½ä½“ç³»ç»Ÿåˆ†æ
                with st.spinner("å•æ™ºèƒ½ä½“ç³»ç»Ÿæ­£åœ¨åˆ†æ..."):
                    final_mono_output = monolithic_agent.invoke({
                        "messages": [
                            SystemMessage(content="ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„é‡‘èåˆ†æå¸ˆã€‚ä½ å¿…é¡»åˆ›å»ºä¸€ä»½å…¨é¢çš„æŠ¥å‘Šï¼Œæ¶µç›–ç”¨æˆ·è¯·æ±‚çš„æ‰€æœ‰æ–¹é¢ã€‚"),
                            HumanMessage(content=analysis_query)
                        ]
                    })
                
                # å±•ç¤ºå•æ™ºèƒ½ä½“åˆ†æç»“æœ
                mono_message = final_mono_output['messages'][-1].content
                st.markdown(mono_message)
                
                # ä¿å­˜å•æ™ºèƒ½ä½“ç»“æœç”¨äºå¯¹æ¯”
                mono_agent_result = mono_message
            
            if analysis_type == "å¯¹æ¯”åˆ†æ":
                st.markdown("---")
                st.markdown("## ğŸ“Š ç³»ç»Ÿå¯¹æ¯”")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("### ğŸ¤– å•æ™ºèƒ½ä½“ç³»ç»Ÿ")
                    st.markdown("- **ä¼˜ç‚¹**ï¼šç»“æ„ç®€å•ï¼Œå•ä¸€å…¥å£")
                    st.markdown("- **ç¼ºç‚¹**ï¼šåˆ†æå¯èƒ½ä¸å¤Ÿæ·±å…¥ï¼Œå„é¢†åŸŸä¸“ä¸šåº¦æœ‰é™")
                    st.markdown("- **é€‚ç”¨åœºæ™¯**ï¼šç®€å•ä»»åŠ¡ï¼Œå¿«é€Ÿå“åº”")
                
                with col2:
                    st.markdown("### ğŸ‘¥ å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ")
                    st.markdown("- **ä¼˜ç‚¹**ï¼šå„é¢†åŸŸåˆ†ææ›´æ·±å…¥ï¼Œä¸“ä¸šåº¦æ›´é«˜ï¼Œç»“æœæ›´å…¨é¢")
                    st.markdown("- **ç¼ºç‚¹**ï¼šç»“æ„å¤æ‚ï¼Œéœ€è¦æ›´å¤šçš„åè°ƒå’Œèµ„æº")
                    st.markdown("- **é€‚ç”¨åœºæ™¯**ï¼šå¤æ‚ä»»åŠ¡ï¼Œéœ€è¦å¤šé¢†åŸŸä¸“ä¸šçŸ¥è¯†")

def visualize_planner_executor_verifier():
    """å¯è§†åŒ–è§„åˆ’â†’æ‰§è¡Œâ†’éªŒè¯æ™ºèƒ½ä½“"""
    st.markdown("### 06 - è§„åˆ’â†’æ‰§è¡Œâ†’éªŒè¯æ™ºèƒ½ä½“ (Plannerâ†’Executorâ†’Verifier)")
    
    # åŠ è½½06_planner_executor_verifieræ¨¡å—
    spec = importlib.util.spec_from_file_location("planner_executor_verifier", "06_planner_executor_verifier.py")
    planner_executor_verifier = importlib.util.module_from_spec(spec)
    sys.modules["planner_executor_verifier"] = planner_executor_verifier
    spec.loader.exec_module(planner_executor_verifier)
    
    # ä»æ¨¡å—ä¸­å¯¼å…¥æ‰€éœ€å‡½æ•°å’Œç±»
    init_llm = planner_executor_verifier.init_llm
    build_app = planner_executor_verifier.build_app
    run_workflow = planner_executor_verifier.run_workflow
    print_execution_results = planner_executor_verifier.print_execution_results
    
    # ç”¨æˆ·è¾“å…¥åŒºåŸŸ
    default_request = "æŸ¥è¯¢è‹¹æœå…¬å¸ä¸Šä¸€è´¢å¹´çš„ç ”å‘æ”¯å‡ºå’Œå‘˜å·¥æ•°é‡ï¼Œè®¡ç®—äººå‡ç ”å‘æ”¯å‡º"
    user_request = st.text_area("è¾“å…¥æ‚¨çš„è¯·æ±‚", value=default_request, height=100)
    
    # æ‰§è¡ŒæŒ‰é’®
    if st.button("å¼€å§‹æ‰§è¡Œè§„åˆ’â†’æ‰§è¡Œâ†’éªŒè¯å·¥ä½œæµ"):
        # æ£€æŸ¥APIå¯†é’¥
        if not os.environ.get("MODELSCOPE_API_KEY"):
            st.error("è¯·å…ˆè®¾ç½®APIå¯†é’¥")
        else:
            with st.spinner("æ­£åœ¨åˆå§‹åŒ–ç³»ç»Ÿ..."):
                # åˆå§‹åŒ–LLM
                llm = init_llm()
                
                # æ„å»ºå·¥ä½œæµ
                app = build_app(llm)
            
            st.success("ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼")
            
            # åˆ›å»ºæ—¥å¿—æ˜¾ç¤ºåŒºåŸŸ
            logs_container = st.empty()
            log_content = ""
            
            # é‡å®šå‘æ§åˆ¶å°è¾“å‡ºåˆ°æ—¥å¿—åŒºåŸŸ
            import io
            from contextlib import redirect_stdout
            
            f = io.StringIO()
            with redirect_stdout(f):
                # æ‰§è¡Œå·¥ä½œæµ
                final_state = run_workflow(app, user_request)
                
            # è·å–æ§åˆ¶å°è¾“å‡º
            log_content = f.getvalue()
            
            # æ˜¾ç¤ºæ—¥å¿—
            st.markdown("### æ‰§è¡Œæ—¥å¿—")
            st.text_area("", value=log_content, height=300, disabled=True)
            
            # æ˜¾ç¤ºç»“æœ
            st.markdown("### æ‰§è¡Œç»“æœ")
            
            # æ˜¾ç¤ºæ‰§è¡Œè¿‡ç¨‹
            if "intermediate_steps" in final_state:
                st.markdown("#### 1. æ‰§è¡Œæ­¥éª¤")
                for i, step in enumerate(final_state["intermediate_steps"]):
                    st.markdown(f"**æ­¥éª¤ {i+1}**ï¼š{step}")
                    st.markdown("")
            
            # æ˜¾ç¤ºæœ€ç»ˆç­”æ¡ˆ
            if "final_answer" in final_state and final_state["final_answer"]:
                st.markdown("#### 2. æœ€ç»ˆç­”æ¡ˆ")
                st.markdown(final_state["final_answer"])


def visualize_blackboard_system():
    """å¯è§†åŒ–é»‘æ¿ç³»ç»Ÿ"""
    st.markdown("### 07 - é»‘æ¿ç³»ç»Ÿ (Blackboard System)")
    
    # åŠ è½½07_blackboardæ¨¡å—
    spec = importlib.util.spec_from_file_location("blackboard", "07_blackboard.py")
    blackboard = importlib.util.module_from_spec(spec)
    sys.modules["blackboard"] = blackboard
    spec.loader.exec_module(blackboard)
    
    # ä»æ¨¡å—ä¸­å¯¼å…¥æ‰€éœ€å‡½æ•°å’Œç±»
    init_llm = blackboard.init_llm
    build_blackboard_system = blackboard.build_blackboard_system
    run_blackboard_system = blackboard.run_blackboard_system
    search_tool = blackboard.search_tool
    
    # ç”¨æˆ·è¾“å…¥åŒºåŸŸ
    default_request = "æŸ¥æ‰¾ NVIDIA çš„æœ€æ–°é‡å¤§æ–°é—»ã€‚æ ¹æ®è¯¥æ–°é—»çš„æƒ…ç»ªï¼Œè¿›è¡ŒæŠ€æœ¯åˆ†æï¼ˆå¦‚æœæ–°é—»æ˜¯ä¸­æ€§æˆ–ç§¯æçš„ï¼‰æˆ–è´¢åŠ¡åˆ†æï¼ˆå¦‚æœæ–°é—»æ˜¯è´Ÿé¢çš„ï¼‰ã€‚"
    user_request = st.text_area("è¾“å…¥æ‚¨çš„è¯·æ±‚", value=default_request, height=100)
    
    # æ‰§è¡ŒæŒ‰é’®
    if st.button("å¼€å§‹æ‰§è¡Œé»‘æ¿ç³»ç»Ÿå·¥ä½œæµ"):
        # æ£€æŸ¥APIå¯†é’¥
        if not os.environ.get("MODELSCOPE_API_KEY"):
            st.error("è¯·å…ˆè®¾ç½®APIå¯†é’¥")
        else:
            with st.spinner("æ­£åœ¨åˆå§‹åŒ–ç³»ç»Ÿ..."):
                # åˆå§‹åŒ–LLM
                llm = init_llm()
                
                # æ„å»ºé»‘æ¿ç³»ç»Ÿ
                blackboard_app = build_blackboard_system(llm, search_tool)
            
            st.success("ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼")
            
            # åˆ›å»ºæ—¥å¿—æ˜¾ç¤ºåŒºåŸŸ
            logs_container = st.empty()
            log_content = ""
            
            # é‡å®šå‘æ§åˆ¶å°è¾“å‡ºåˆ°æ—¥å¿—åŒºåŸŸ
            import io
            from contextlib import redirect_stdout
            
            f = io.StringIO()
            with redirect_stdout(f):
                # æ‰§è¡Œå·¥ä½œæµ
                final_result = run_blackboard_system(blackboard_app, user_request)
                
            # è·å–æ§åˆ¶å°è¾“å‡º
            log_content = f.getvalue()
            
            # æ˜¾ç¤ºæ—¥å¿—
            st.markdown("### æ‰§è¡Œæ—¥å¿—")
            st.text_area("", value=log_content, height=300, disabled=True)
            
            # æ˜¾ç¤ºç»“æœ
            st.markdown("### æ‰§è¡Œç»“æœ")
            
            # æ˜¾ç¤ºæœ€ç»ˆæŠ¥å‘Š
            for item in final_result["blackboard"]:
                if "[æŠ¥å‘Šæ’°å†™è€…]" in item:
                    st.markdown("#### 1. æœ€ç»ˆæŠ¥å‘Š")
                    st.markdown(item.replace("[æŠ¥å‘Šæ’°å†™è€…]", ""))
                    break
            
            # æ˜¾ç¤ºä¿¡æ¯æ¿å®Œæ•´å†…å®¹
            st.markdown("#### 2. ä¿¡æ¯æ¿å®Œæ•´å†…å®¹")
            for i, item in enumerate(final_result["blackboard"]):
                st.markdown(f"**[{i+1}] {item.splitlines()[0]}**")
                content = "\n".join(item.splitlines()[1:])
                st.markdown(content)
                st.markdown("")

# æ·»åŠ æ€ç»´æ ‘æ™ºèƒ½ä½“çš„å¯è§†åŒ–å‡½æ•°
def visualize_tree_of_thoughts():
    """å¯è§†åŒ–æ€ç»´æ ‘æ™ºèƒ½ä½“"""
    st.markdown("### 09 - æ€ç»´æ ‘æ™ºèƒ½ä½“ (Tree-of-Thoughts)")
    
    # åŠ è½½09_tree_of_thoughts_cnæ¨¡å—
    spec = importlib.util.spec_from_file_location("tree_of_thoughts", "09_tree_of_thoughts_cn.py")
    tot = importlib.util.module_from_spec(spec)
    sys.modules["tree_of_thoughts"] = tot
    spec.loader.exec_module(tot)
    
    # ç”¨æˆ·è¾“å…¥åŒºåŸŸ
    default_request = "ä»æ•°å­—1å¼€å§‹ï¼Œä½¿ç”¨+1ã€Ã—3ã€-2æ“ä½œï¼Œåœ¨8æ­¥å†…åˆ°è¾¾æ•°å­—29"
    user_request = st.text_area("è¾“å…¥æ‚¨çš„è¯·æ±‚", value=default_request, height=100)
    
    # æ‰§è¡ŒæŒ‰é’®
    if st.button("å¼€å§‹æ‰§è¡Œæ€ç»´æ ‘å·¥ä½œæµ"):
        # æ£€æŸ¥APIå¯†é’¥
        if not os.environ.get("MODELSCOPE_API_KEY"):
            st.error("è¯·å…ˆè®¾ç½®APIå¯†é’¥")
        else:
            # åˆ›å»ºæ—¥å¿—æ˜¾ç¤ºåŒºåŸŸ
            logs_container = st.empty()
            log_content = ""
            
            # é‡å®šå‘æ§åˆ¶å°è¾“å‡ºåˆ°æ—¥å¿—åŒºåŸŸ
            import io
            from contextlib import redirect_stdout
            
            f = io.StringIO()
            with redirect_stdout(f):
                # ä»æ¨¡å—ä¸­å¯¼å…¥æ‰€éœ€å‡½æ•°å’Œå˜é‡
                tot_agent = tot.tot_agent
                CONFIG = tot.CONFIG
                
                # æ‰§è¡Œå·¥ä½œæµ
                result = tot_agent.invoke({
                    "problem_description": user_request,
                    "active_paths": [],
                    "solution": None
                })
            
            # è·å–æ§åˆ¶å°è¾“å‡º
            log_content = f.getvalue()
            
            # æ˜¾ç¤ºæ—¥å¿—
            st.markdown("### æ‰§è¡Œæ—¥å¿—")
            st.text_area("", value=log_content, height=300, disabled=True)
            
            # æ˜¾ç¤ºç»“æœ
            st.markdown("### æ‰§è¡Œç»“æœ")
            
            # æ˜¾ç¤ºè§£å†³æ–¹æ¡ˆè·¯å¾„
            if result.get("solution"):
                solution_path = result["solution"]
                
                # åˆ›å»ºå¯è§†åŒ–è·¯å¾„æ ‘
                from rich.tree import Tree
                from rich.console import Console
                
                path_tree = Tree("[bold blue]ğŸ“ˆ è§£å†³æ–¹æ¡ˆè·¯å¾„[/bold blue]")
                for i, state in enumerate(solution_path):
                    node_label = f"[{i+1}] {state.move_description}"
                    node = path_tree.add(node_label)
                    node.add(f"å½“å‰æ•°å­—: {state.current_number} | å·²èµ°æ­¥æ•°: {state.steps_taken}")
                
                # æ˜¾ç¤ºæ ‘çŠ¶å›¾
                console = Console(width=80)
                with redirect_stdout(f):
                    console.print(path_tree)
                tree_output = f.getvalue()
                
                st.text_area("è·¯å¾„å¯è§†åŒ–", value=tree_output, height=300, disabled=True)
                
                # æ˜¾ç¤ºè§£å†³æ–¹æ¡ˆç»Ÿè®¡
                st.markdown("#### è§£å†³æ–¹æ¡ˆç»Ÿè®¡")
                st.markdown(f"**æ€»æ­¥æ•°:** {solution_path[-1].steps_taken}")
                st.markdown(f"**è·¯å¾„åºåˆ—:** {' â†’ '.join(map(str, solution_path[-1].path))}")
                st.markdown(f"**è§£å†³æ•ˆç‡:** {(1 - (solution_path[-1].steps_taken / CONFIG['MAX_STEPS'])) * 100:.1f}% ({CONFIG['MAX_STEPS']}æ­¥é™åˆ¶)")
            else:
                st.markdown("[red]æœªæ‰¾åˆ°è§£å†³æ–¹æ¡ˆã€‚[/red]")

# æ·»åŠ æƒ…æ™¯è®°å¿†+è¯­ä¹‰è®°å¿†æ ˆæ™ºèƒ½ä½“çš„å¯è§†åŒ–å‡½æ•°
def visualize_episodic_with_semantic():
    """å¯è§†åŒ–æƒ…æ™¯è®°å¿†+è¯­ä¹‰è®°å¿†æ ˆæ™ºèƒ½ä½“"""
    st.markdown("### 08 - æƒ…æ™¯è®°å¿†+è¯­ä¹‰è®°å¿†æ ˆ (Episodic+Semantic Memory Stack)")
    
    # åŠ è½½08_episodic_with_semantic_cnæ¨¡å—
    spec = importlib.util.spec_from_file_location("episodic_with_semantic", "08_episodic_with_semantic_cn.py")
    ewsm = importlib.util.module_from_spec(spec)
    sys.modules["episodic_with_semantic"] = ewsm
    spec.loader.exec_module(ewsm)
    
    # ä»æ¨¡å—ä¸­å¯¼å…¥æ‰€éœ€å‡½æ•°å’Œç±»
    init_llm = ewsm.init_llm
    EpisodicMemoryStore = ewsm.EpisodicMemoryStore
    SemanticMemoryGraph = ewsm.SemanticMemoryGraph
    run_conversation = ewsm.run_conversation
    
    # ç”¨æˆ·è¾“å…¥åŒºåŸŸ
    default_request = "æˆ‘å¯¹ç§‘æŠ€è‚¡å¾ˆæ„Ÿå…´è¶£ï¼Œç‰¹åˆ«æ˜¯NVIDIAå’ŒAMDã€‚ä½ èƒ½ç»™æˆ‘ä¸€äº›æŠ•èµ„å»ºè®®å—ï¼Ÿ"
    user_request = st.text_area("è¾“å…¥æ‚¨çš„è¯·æ±‚", value=default_request, height=100)
    
    # æ‰§è¡ŒæŒ‰é’®
    if st.button("å¼€å§‹æ‰§è¡Œå¯¹è¯"):
        # æ£€æŸ¥APIå¯†é’¥
        if not os.environ.get("MODELSCOPE_API_KEY"):
            st.error("è¯·å…ˆè®¾ç½®APIå¯†é’¥")
        else:
            # åˆ›å»ºæ—¥å¿—æ˜¾ç¤ºåŒºåŸŸ
            logs_container = st.empty()
            log_content = ""
            
            # é‡å®šå‘æ§åˆ¶å°è¾“å‡ºåˆ°æ—¥å¿—åŒºåŸŸ
            import io
            from contextlib import redirect_stdout
            
            f = io.StringIO()
            with redirect_stdout(f):
                # æ‰§è¡Œå¯¹è¯
                final_response, _ = run_conversation(user_request)
            
            # è·å–æ§åˆ¶å°è¾“å‡º
            log_content = f.getvalue()
            
            # æ˜¾ç¤ºæ—¥å¿—
            st.markdown("### æ‰§è¡Œæ—¥å¿—")
            st.text_area("", value=log_content, height=300, disabled=True)
            
            # æ˜¾ç¤ºç»“æœ
            st.markdown("### æ‰§è¡Œç»“æœ")
            st.markdown("#### æœ€ç»ˆå“åº”")
            st.markdown(final_response)

# æ·»åŠ æ€ç»´æ¨¡å‹å¾ªç¯æ™ºèƒ½ä½“çš„å¯è§†åŒ–å‡½æ•°
def visualize_mental_loop():
    """å¯è§†åŒ–æ€ç»´æ¨¡å‹å¾ªç¯æ™ºèƒ½ä½“"""
    st.markdown("### 10 - æ€ç»´æ¨¡å‹å¾ªç¯æ™ºèƒ½ä½“ (Mental-Model-in-the-Loop)")
    
    # åŠ è½½10_mental_loop_cnæ¨¡å—
    spec = importlib.util.spec_from_file_location("mental_loop", "10_mental_loop_cn.py")
    ml = importlib.util.module_from_spec(spec)
    sys.modules["mental_loop"] = ml
    spec.loader.exec_module(ml)
    
    # ç”¨æˆ·è¾“å…¥åŒºåŸŸ
    st.markdown("#### å¸‚åœºæ¨¡æ‹Ÿæ¼”ç¤º")
    st.markdown("è¿™ä¸ªæ¼”ç¤ºå±•ç¤ºäº†æ€ç»´æ¨¡å‹å¾ªç¯æ¶æ„å¦‚ä½•åœ¨è‚¡ç¥¨äº¤æ˜“åœºæ™¯ä¸­å·¥ä½œã€‚")
    st.markdown("æ™ºèƒ½ä½“å°†åœ¨æ¨¡æ‹Ÿå¸‚åœºä¸­è¿è¡Œ3å¤©ï¼Œå¤„ç†å¥½æ¶ˆæ¯ã€åæ¶ˆæ¯å’Œå¸‚åœºç¨³å®šçš„æƒ…å†µã€‚")
    
    # æ‰§è¡ŒæŒ‰é’®
    if st.button("å¼€å§‹æ‰§è¡Œå¸‚åœºæ¨¡æ‹Ÿ"):
        # æ£€æŸ¥APIå¯†é’¥
        if not os.environ.get("MODELSCOPE_API_KEY"):
            st.warning("æœªè®¾ç½®MODELSCOPE_API_KEYç¯å¢ƒå˜é‡ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿå“åº”è¿›è¡Œæ¼”ç¤ºã€‚")
        
        # åˆ›å»ºæ—¥å¿—æ˜¾ç¤ºåŒºåŸŸ
        logs_container = st.empty()
        log_content = ""
        
        # é‡å®šå‘æ§åˆ¶å°è¾“å‡ºåˆ°æ—¥å¿—åŒºåŸŸ
        import io
        from contextlib import redirect_stdout
        import sys
        
        # é‡å®šå‘inputå‡½æ•°ï¼Œé¿å…é˜»å¡
        original_input = sys.stdin.readline
        def mock_input(prompt=""):
            return ""
        
        sys.stdin.readline = mock_input
        
        try:
            f = io.StringIO()
            with redirect_stdout(f):
                # æ‰§è¡Œæ¼”ç¤º
                ml.run_demo()
        finally:
            # æ¢å¤åŸå§‹inputå‡½æ•°
            sys.stdin.readline = original_input
        
        # è·å–æ§åˆ¶å°è¾“å‡º
        log_content = f.getvalue()
        
        # æ˜¾ç¤ºæ—¥å¿—
        st.markdown("### æ‰§è¡Œæ—¥å¿—")
        st.text_area("", value=log_content, height=400, disabled=True)


def visualize_meta_controller():
    """å¯è§†åŒ–å…ƒæ§åˆ¶å™¨æ™ºèƒ½ä½“"""
    st.markdown("### 11 - å…ƒæ§åˆ¶å™¨æ™ºèƒ½ä½“ (Meta-Controller)")

    # åŠ è½½ 11_meta_controller_cn æ¨¡å—
    spec = importlib.util.spec_from_file_location("meta_controller", "11_meta_controller_cn.py")
    mc = importlib.util.module_from_spec(spec)
    sys.modules["meta_controller"] = mc
    spec.loader.exec_module(mc)

    run_agent = mc.run_agent

    st.markdown("å…ƒæ§åˆ¶å™¨åˆ†æç”¨æˆ·è¯·æ±‚å¹¶è·¯ç”±åˆ°æœ€åˆé€‚çš„ä¸“å®¶ï¼ˆé€šç”¨/ç ”ç©¶/ç¼–ç ï¼‰ã€‚")
    default_query = "ä½ å¥½ï¼Œä»Šå¤©æ€ä¹ˆæ ·ï¼Ÿ"
    user_query = st.text_area("è¾“å…¥æ‚¨çš„è¯·æ±‚", value=default_query, height=80)

    if st.button("è¿è¡Œå…ƒæ§åˆ¶å™¨"):
        if not os.environ.get("MODELSCOPE_API_KEY"):
            st.warning("æœªè®¾ç½® MODELSCOPE_API_KEYï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿå“åº”ï¼ˆè‹¥è„šæœ¬æ”¯æŒï¼‰ã€‚")
        import io
        from contextlib import redirect_stdout

        f = io.StringIO()
        try:
            with redirect_stdout(f):
                run_agent(user_query)
        except Exception as e:
            st.error(f"æ‰§è¡Œå‡ºé”™: {e}")
            st.code(str(e))
        log_content = f.getvalue()
        st.markdown("### æ‰§è¡Œæ—¥å¿—")
        st.text_area("", value=log_content, height=400, disabled=True)


def visualize_graph():
    """å¯è§†åŒ–å›¾/ä¸–ç•Œæ¨¡å‹è®°å¿†æ™ºèƒ½ä½“ï¼ˆçŸ¥è¯†å›¾è°±æ„å»ºä¸å¤šè·³é—®ç­”ï¼‰"""
    st.markdown("### 12 - å›¾/ä¸–ç•Œæ¨¡å‹è®°å¿† (Graph)")

    spec = importlib.util.spec_from_file_location("graph_cn", "12_graph_cn.py")
    gc = importlib.util.module_from_spec(spec)
    sys.modules["graph_cn"] = gc
    spec.loader.exec_module(gc)

    init_llm = gc.init_llm
    get_graph = gc.get_graph
    get_graph_maker_chain = gc.get_graph_maker_chain
    ingest_documents = gc.ingest_documents
    query_graph = gc.query_graph

    st.markdown("ä»æ–‡æœ¬æŠ½å–çŸ¥è¯†å›¾è°±å¹¶å†™å…¥å›¾ï¼Œå†æ ¹æ®è‡ªç„¶è¯­è¨€é—®é¢˜ç”Ÿæˆ Cypher æŸ¥è¯¢å¹¶åˆæˆç­”æ¡ˆã€‚")
    if st.button("1. æ„å»ºçŸ¥è¯†å›¾è°±ï¼ˆæ‘„å…¥é»˜è®¤ 3 æ®µæ–‡æ¡£ï¼‰"):
        if not os.environ.get("MODELSCOPE_API_KEY"):
            st.warning("æœªè®¾ç½® MODELSCOPE_API_KEYï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿå“åº”ã€‚")
        import io
        from contextlib import redirect_stdout
        f = io.StringIO()
        try:
            with redirect_stdout(f):
                llm = init_llm()
                graph = get_graph()
                graph_maker_invoke = get_graph_maker_chain(llm)
                ingest_documents(graph, graph_maker_invoke)
            st.success("çŸ¥è¯†å›¾è°±æ„å»ºå®Œæˆ")
            st.text_area("æ‘„å…¥æ—¥å¿—", value=f.getvalue(), height=200, disabled=True)
            st.session_state["graph_llm"] = (graph, llm)
        except Exception as e:
            st.error(str(e))
            st.code(str(e))

    question = st.text_input("2. è¾“å…¥å›¾é—®ç­”é—®é¢˜", value="è°åœ¨ AlphaCorp å·¥ä½œï¼Ÿ", key="graph_question")
    if st.button("æ‰§è¡Œå›¾é—®ç­”"):
        if "graph_llm" not in st.session_state:
            st.warning("è¯·å…ˆç‚¹å‡»ã€Œ1. æ„å»ºçŸ¥è¯†å›¾è°±ã€å†æ‰§è¡Œé—®ç­”ã€‚")
        elif not os.environ.get("MODELSCOPE_API_KEY"):
            st.warning("æœªè®¾ç½® MODELSCOPE_API_KEYï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿå“åº”ã€‚")
        else:
            graph, llm = st.session_state["graph_llm"]
            import io
            from contextlib import redirect_stdout
            f = io.StringIO()
            try:
                with redirect_stdout(f):
                    result = query_graph(graph, llm, question)
                st.markdown("### ç­”æ¡ˆ")
                st.markdown(result["answer"])
                st.text_area("æ‰§è¡Œæ—¥å¿—", value=f.getvalue(), height=250, disabled=True)
            except Exception as e:
                st.error(str(e))
                st.code(str(e))


def visualize_ensemble():
    """å¯è§†åŒ–å¹¶è¡Œæ¢ç´¢+é›†æˆå†³ç­–ï¼ˆæŠ•èµ„å§”å‘˜ä¼šï¼‰"""
    st.markdown("### 13 - å¹¶è¡Œæ¢ç´¢+é›†æˆå†³ç­– (Ensemble)")
    spec = importlib.util.spec_from_file_location("ensemble_cn", "13_ensemble_cn.py")
    mod = importlib.util.module_from_spec(spec)
    sys.modules["ensemble_cn"] = mod
    spec.loader.exec_module(mod)
    init_llm = mod.init_llm
    build_app = mod.build_app
    run_workflow = mod.run_workflow
    st.markdown("ä¸‰è·¯åˆ†æå¸ˆï¼ˆçœ‹å¤š/ä»·å€¼/é‡åŒ–ï¼‰å¹¶è¡Œåˆ†æï¼ŒCIO ç»¼åˆè¾“å‡ºæŠ•èµ„å»ºè®®ã€‚")
    request = st.text_area("æŠ•èµ„åˆ†æé—®é¢˜", value="åŸºäºè¿‘æœŸæ–°é—»ã€è´¢åŠ¡è¡¨ç°ä¸å±•æœ›ï¼Œè‹±ä¼Ÿè¾¾ï¼ˆNVDAï¼‰åœ¨ 2026 å¹´ä¸‹åŠå¹´æ˜¯å¦å€¼å¾—é•¿æœŸæŠ•èµ„ï¼Ÿ", height=80)
    if st.button("å¼€å§‹æ‰§è¡ŒæŠ•èµ„å§”å‘˜ä¼šå·¥ä½œæµ"):
        if not os.environ.get("MODELSCOPE_API_KEY"):
            st.warning("æœªè®¾ç½® MODELSCOPE_API_KEYï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿå“åº”ã€‚")
        import io
        from contextlib import redirect_stdout
        f = io.StringIO()
        try:
            with redirect_stdout(f):
                llm = init_llm()
                app = build_app(llm)
                result = run_workflow(app, request)
            st.success("æ‰§è¡Œå®Œæˆ")
            st.text_area("æ‰§è¡Œæ—¥å¿—", value=f.getvalue(), height=300, disabled=True)
            if result.get("analyses"):
                for name, text in result["analyses"].items():
                    st.markdown(f"**{name}**")
                    st.markdown(text[:500] + "..." if len(text) > 500 else text)
            rec = result.get("final_recommendation")
            if rec:
                st.markdown("**CIO ç»¼åˆå»ºè®®**")
                st.markdown(f"- æœ€ç»ˆå»ºè®®ï¼š{rec.final_recommendation}ï¼Œä¿¡å¿ƒï¼š{rec.confidence_score}/10")
                st.markdown(f"- ç»¼åˆæ‘˜è¦ï¼š{rec.synthesis_summary}")
        except Exception as e:
            st.error(str(e))
            st.code(str(e))


def visualize_dry_run():
    """å¯è§†åŒ–å¯è§‚æµ‹ä¸è¯•è·‘å¤–å£³ï¼ˆæ‹Ÿå‘å¸–â†’è¯•è·‘â†’å®¡æ ¸â†’æ‰§è¡Œ/å–æ¶ˆï¼‰"""
    st.markdown("### 14 - å¯è§‚æµ‹ä¸è¯•è·‘å¤–å£³ (Dry-Run Harness)")
    spec = importlib.util.spec_from_file_location("dry_run_cn", "14_dry_run_cn.py")
    mod = importlib.util.module_from_spec(spec)
    sys.modules["dry_run_cn"] = mod
    spec.loader.exec_module(mod)
    init_llm = mod.init_llm
    build_app = mod.build_app
    run_workflow = mod.run_workflow
    st.markdown("æ‹Ÿç¨¿ â†’ è¯•è·‘é¢„è§ˆ â†’ äººå·¥å®¡æ ¸ï¼ˆapprove/rejectï¼‰â†’ æ‰§è¡Œæˆ–å–æ¶ˆã€‚ä¸‹æ–¹é€‰æ‹©ã€Œæ¨¡æ‹Ÿå®¡æ ¸ã€ç»“æœåæ‰§è¡Œã€‚")
    request = st.text_area("å‘å¸–è¯·æ±‚", value="ä¸ºæˆ‘ä»¬çš„æ–° AI æ¨¡å‹ã€Œæ˜Ÿäº‘ã€å†™ä¸€æ¡æ­£é¢å‘å¸ƒå…¬å‘Šã€‚", height=60)
    dry_run_decision = st.radio("æ¨¡æ‹Ÿå®¡æ ¸å†³ç­–", ["approve", "reject"], horizontal=True)
    if st.button("å¼€å§‹æ‰§è¡Œè¯•è·‘å·¥ä½œæµ"):
        if not os.environ.get("MODELSCOPE_API_KEY"):
            st.warning("æœªè®¾ç½® MODELSCOPE_API_KEYï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿå“åº”ã€‚")
        import io
        from contextlib import redirect_stdout
        _orig_console_input = mod.console.input
        mod.console.input = lambda prompt="": dry_run_decision
        f = io.StringIO()
        try:
            with redirect_stdout(f):
                llm = init_llm()
                app = build_app(llm)
                result = run_workflow(app, request)
            st.success("æ‰§è¡Œå®Œæˆ")
            st.text_area("æ‰§è¡Œæ—¥å¿—", value=f.getvalue(), height=300, disabled=True)
            st.markdown(f"**æœ€ç»ˆçŠ¶æ€**ï¼š{result.get('final_status', '')}")
        except Exception as e:
            st.error(str(e))
            st.code(str(e))
        finally:
            mod.console.input = _orig_console_input


def visualize_self_refine():
    """å¯è§†åŒ–è‡ªæ”¹è¿›å¾ªç¯ï¼ˆç”Ÿæˆâ†’è¯„å®¡â†’ä¿®è®¢ï¼‰"""
    st.markdown("### 15 - è‡ªæ”¹è¿›å¾ªç¯ (Self-Refine / RLHF)")
    spec = importlib.util.spec_from_file_location("rlhf_cn", "15_RLHF_cn.py")
    mod = importlib.util.module_from_spec(spec)
    sys.modules["rlhf_cn"] = mod
    spec.loader.exec_module(mod)
    init_llm = mod.init_llm
    build_app = mod.build_app
    run_workflow = mod.run_workflow
    st.markdown("ç”Ÿæˆè¥é”€é‚®ä»¶åˆç¨¿ â†’ è¯„å®¡ï¼ˆ8 åˆ†é€šè¿‡ï¼‰â†’ æœªé€šè¿‡åˆ™ä¿®è®¢å†è¯„å®¡ï¼Œæœ€å¤š 3 è½®ã€‚")
    request = st.text_area("é‚®ä»¶è¯·æ±‚", value="ä¸ºæˆ‘ä»¬æ–°çš„ AI æ•°æ®åˆ†æå¹³å°ã€ŒInsightSphereã€å†™ä¸€å°è¥é”€é‚®ä»¶ã€‚", height=80)
    if st.button("å¼€å§‹æ‰§è¡Œè‡ªæ”¹è¿›å·¥ä½œæµ"):
        if not os.environ.get("MODELSCOPE_API_KEY"):
            st.warning("æœªè®¾ç½® MODELSCOPE_API_KEYï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿå“åº”ã€‚")
        import io
        from contextlib import redirect_stdout
        f = io.StringIO()
        try:
            with redirect_stdout(f):
                llm = init_llm()
                app = build_app(llm)
                result = run_workflow(app, request)
            st.success("æ‰§è¡Œå®Œæˆ")
            st.text_area("æ‰§è¡Œæ—¥å¿—", value=f.getvalue(), height=300, disabled=True)
            d = result.get("draft_email")
            c = result.get("critique")
            if d:
                st.markdown("**æœ€ç»ˆé‚®ä»¶**")
                st.markdown(f"ä¸»é¢˜ï¼š{d.subject}")
                st.markdown(d.body)
                if c:
                    st.markdown(f"è¯„å®¡åˆ†æ•°ï¼š{c.score}/10")
        except Exception as e:
            st.error(str(e))
            st.code(str(e))


def visualize_cellular_automata():
    """å¯è§†åŒ–ç»†èƒè‡ªåŠ¨æœº/ç½‘æ ¼æ‹£è´§"""
    st.markdown("### 16 - ç»†èƒè‡ªåŠ¨æœº/ç½‘æ ¼æ™ºèƒ½ä½“ (Cellular Automata)")
    spec = importlib.util.spec_from_file_location("cellular_cn", "16_cellular_automata_cn.py")
    mod = importlib.util.module_from_spec(spec)
    sys.modules["cellular_cn"] = mod
    spec.loader.exec_module(mod)
    WarehouseGrid = mod.WarehouseGrid
    DEFAULT_LAYOUT = mod.DEFAULT_LAYOUT
    fulfill_order = mod.fulfill_order
    st.markdown("ä»æ‰“åŒ…ç«™æ‰©æ•£è·¯å¾„æ³¢ï¼Œæ²¿æ¢¯åº¦ä»è´§æ¶æ‹£è´§åˆ°æ‰“åŒ…ç«™ã€‚è¾“å…¥æ‹£è´§æ¸…å•ï¼ˆé€—å·åˆ†éš”ï¼Œå¦‚ A,Bï¼‰ã€‚")
    order_str = st.text_input("æ‹£è´§æ¸…å•", value="A,B")
    verbose_mode = st.checkbox("æ™ºèƒ½ä½“ç¾¤ç»„æ¼”ç¤ºï¼ˆæ‰“å°æ¯ tick å„æ ¼å­æ›´æ–°è¿‡ç¨‹ï¼‰", value=False)
    if st.button("å¼€å§‹æ‰§è¡Œæ‹£è´§"):
        import io
        from contextlib import redirect_stdout
        order = [x.strip() for x in order_str.split(",") if x.strip()] or ["A", "B"]
        f = io.StringIO()
        try:
            with redirect_stdout(f):
                grid = WarehouseGrid(DEFAULT_LAYOUT)
                mod.console.print("--- åˆå§‹ç½‘æ ¼ ---")
                grid.visualize()
                mod.console.print(f"\n--- æ‹£è´§æ¸…å•ï¼š{order} ---")
                results = fulfill_order(grid, order, verbose=verbose_mode)
            st.success("æ‹£è´§å®Œæˆ")
            st.text_area("æ‰§è¡Œæ—¥å¿—", value=f.getvalue(), height=350, disabled=True)
            if results:
                for item, path in results:
                    st.markdown(f"**{item}** è·¯å¾„ï¼š{' â†’ '.join(str(p) for p in path)}")
        except Exception as e:
            st.error(str(e))
            st.code(str(e))


def visualize_metacognitive():
    """å¯è§†åŒ–åæ€å¼å…ƒè®¤çŸ¥ï¼ˆåŒ»ç–—åˆ†è¯Šï¼‰"""
    st.markdown("### 17 - åæ€å¼å…ƒè®¤çŸ¥ (Reflexive Metacognitive)")
    spec = importlib.util.spec_from_file_location("meta_cn", "17_reflexive_metacognitive_cn.py")
    mod = importlib.util.module_from_spec(spec)
    sys.modules["meta_cn"] = mod
    spec.loader.exec_module(mod)
    init_llm = mod.init_llm
    build_app = mod.build_app
    run_agent = mod.run_agent
    MEDICAL_SELF_MODEL = mod.MEDICAL_SELF_MODEL
    st.markdown("å…ˆå…ƒè®¤çŸ¥åˆ†æï¼Œå†è·¯ç”±ï¼šç›´æ¥å›ç­” / ç”¨å·¥å…·ï¼ˆè¯ç‰©ç›¸äº’ä½œç”¨ï¼‰/ å‡çº§äººå·¥ã€‚")
    default_query = "å¸ƒæ´›èŠ¬å’Œèµ–è¯ºæ™®åˆ©èƒ½ä¸€èµ·åƒå—ï¼Ÿ"
    query = st.text_area("ç”¨æˆ·é—®é¢˜", value=default_query, height=80, key="meta_query")
    st.caption("é¢„è®¾ç¤ºä¾‹ï¼šç›´æ¥å›ç­”ã€Œæ„Ÿå†’å’Œæµæ„Ÿçš„ç—‡çŠ¶æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿã€ï¼›ç”¨å·¥å…·ã€Œå¸ƒæ´›èŠ¬å’Œèµ–è¯ºæ™®åˆ©èƒ½ä¸€èµ·åƒå—ï¼Ÿã€ï¼›å‡çº§äººå·¥ã€Œæˆ‘èƒ¸å£ç–¼å‘¼å¸å›°éš¾æ€ä¹ˆåŠï¼Ÿã€")
    if st.button("å¼€å§‹æ‰§è¡Œå…ƒè®¤çŸ¥å·¥ä½œæµ"):
        if not os.environ.get("MODELSCOPE_API_KEY"):
            st.warning("æœªè®¾ç½® MODELSCOPE_API_KEYï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿå“åº”ã€‚")
        import io
        from contextlib import redirect_stdout
        f = io.StringIO()
        try:
            with redirect_stdout(f):
                llm = init_llm()
                app = build_app(llm)
                result = run_agent(app, query, MEDICAL_SELF_MODEL)
            st.success("æ‰§è¡Œå®Œæˆ")
            st.text_area("æ‰§è¡Œæ—¥å¿—", value=f.getvalue(), height=250, disabled=True)
            st.markdown("**æœ€ç»ˆå›å¤**")
            st.markdown(result.get("final_response", ""))
        except Exception as e:
            st.error(str(e))
            st.code(str(e))


# æ ¹æ®é€‰æ‹©çš„æ¶æ„æ˜¾ç¤ºä¸åŒçš„å†…å®¹
if "01 - åæ€å‹æ™ºèƒ½ä½“" in selected_architecture:
    visualize_reflection()
elif "02 - å·¥å…·ä½¿ç”¨æ™ºèƒ½ä½“" in selected_architecture:
    visualize_tool_use()
elif "03 - ååº”å‹æ™ºèƒ½ä½“" in selected_architecture:
    visualize_react()
elif "04 - è§„åˆ’å‹æ™ºèƒ½ä½“" in selected_architecture:
    visualize_planning()
elif "05 - å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ" in selected_architecture:
    visualize_multi_agent()
elif "06 - è§„åˆ’â†’æ‰§è¡Œâ†’éªŒè¯æ™ºèƒ½ä½“" in selected_architecture:
    visualize_planner_executor_verifier()
elif "07 - é»‘æ¿ç³»ç»Ÿ" in selected_architecture:
    visualize_blackboard_system()
elif "08 - æƒ…æ™¯è®°å¿†+è¯­ä¹‰è®°å¿†æ ˆ" in selected_architecture:
    visualize_episodic_with_semantic()
elif "09 - æ€ç»´æ ‘æ™ºèƒ½ä½“" in selected_architecture:
    visualize_tree_of_thoughts()
elif "10 - æ€ç»´æ¨¡å‹å¾ªç¯æ™ºèƒ½ä½“" in selected_architecture:
    visualize_mental_loop()
elif "11 - å…ƒæ§åˆ¶å™¨æ™ºèƒ½ä½“" in selected_architecture:
    visualize_meta_controller()
elif "12 - å›¾/ä¸–ç•Œæ¨¡å‹è®°å¿†" in selected_architecture:
    visualize_graph()
elif "13 - å¹¶è¡Œæ¢ç´¢+é›†æˆå†³ç­–" in selected_architecture:
    visualize_ensemble()
elif "14 - å¯è§‚æµ‹ä¸è¯•è·‘å¤–å£³" in selected_architecture:
    visualize_dry_run()
elif "15 - è‡ªæ”¹è¿›å¾ªç¯" in selected_architecture:
    visualize_self_refine()
elif "16 - ç»†èƒè‡ªåŠ¨æœº/ç½‘æ ¼æ™ºèƒ½ä½“" in selected_architecture:
    visualize_cellular_automata()
elif "17 - åæ€å¼å…ƒè®¤çŸ¥" in selected_architecture:
    visualize_metacognitive()

# é¡µè„šä¿¡æ¯
st.markdown("---")
st.markdown("### å…³äºç³»ç»Ÿ")
st.markdown("è¿™æ˜¯ä¸€ä¸ªåŸºäºLangGraphæ„å»ºçš„Agentic Architectureå¯è§†åŒ–ç³»ç»Ÿï¼Œæ”¯æŒå¤šç§æ™ºèƒ½ä½“æ¶æ„çš„äº¤äº’å¼åˆ†æã€‚")
st.markdown("\n### æ¶æ„ç¤ºä¾‹è¯´æ˜")
st.markdown("- **01 - åæ€å‹æ™ºèƒ½ä½“**ï¼šèƒ½å¤Ÿè‡ªæˆ‘åæ€å¹¶æ”¹è¿›è¾“å‡ºçš„æ™ºèƒ½ä½“")
st.markdown("- **02 - å·¥å…·ä½¿ç”¨æ™ºèƒ½ä½“**ï¼šèƒ½å¤Ÿè°ƒç”¨å¤–éƒ¨å·¥å…·è·å–ä¿¡æ¯çš„æ™ºèƒ½ä½“")
st.markdown("- **03 - ååº”å‹æ™ºèƒ½ä½“**ï¼šåŸºäºç¯å¢ƒåé¦ˆåšå‡ºååº”çš„æ™ºèƒ½ä½“")
st.markdown("- **04 - è§„åˆ’å‹æ™ºèƒ½ä½“**ï¼šèƒ½å¤Ÿåˆ¶å®šå’Œæ‰§è¡Œä»»åŠ¡è®¡åˆ’çš„æ™ºèƒ½ä½“")
st.markdown("- **05 - å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ**ï¼šç”±å¤šä¸ªä¸“ä¸šæ™ºèƒ½ä½“ç»„æˆçš„åä½œç³»ç»Ÿ")
st.markdown("- **06 - è§„åˆ’â†’æ‰§è¡Œâ†’éªŒè¯æ™ºèƒ½ä½“**ï¼šèƒ½å¤Ÿæ£€æµ‹å¹¶çº æ­£æ‰§è¡Œé”™è¯¯çš„æ™ºèƒ½ä½“æ¶æ„")
st.markdown("- **07 - é»‘æ¿ç³»ç»Ÿ**ï¼šå¤šæ™ºèƒ½ä½“åä½œçš„é»‘æ¿ç³»ç»Ÿï¼ŒåŒ…å«ä¸“å®¶æ™ºèƒ½ä½“å’ŒåŠ¨æ€æ§åˆ¶å™¨")
st.markdown("- **08 - æƒ…æ™¯è®°å¿†+è¯­ä¹‰è®°å¿†æ ˆ**ï¼šç»“åˆå‘é‡æ•°æ®åº“å’Œå›¾æ•°æ®åº“å®ç°æŒä¹…è®°å¿†çš„æ™ºèƒ½ä½“æ¶æ„")
st.markdown("- **09 - æ€ç»´æ ‘æ™ºèƒ½ä½“**ï¼šé€šè¿‡å¹¶è¡Œæ¢ç´¢å¤šè·¯å¾„ã€è¯„ä¼°ä¿®å‰ªæ— æ•ˆåˆ†æ”¯è§£å†³å¤æ‚é—®é¢˜çš„æ™ºèƒ½ä½“æ¨ç†æ¡†æ¶")
st.markdown("- **10 - æ€ç»´æ¨¡å‹å¾ªç¯æ™ºèƒ½ä½“**ï¼šé€šè¿‡æ¨¡æ‹Ÿå’Œè¯„ä¼°æ½œåœ¨è¡ŒåŠ¨æ¥æé«˜å®‰å…¨æ€§å’Œå‡å°‘é”™è¯¯çš„æ™ºèƒ½ä½“æ¶æ„")
st.markdown("- **11 - å…ƒæ§åˆ¶å™¨æ™ºèƒ½ä½“**ï¼šåˆ†æè¯·æ±‚å¹¶è·¯ç”±åˆ°æœ€åˆé€‚ä¸“å®¶ï¼ˆé€šç”¨/ç ”ç©¶/ç¼–ç ï¼‰çš„ç›‘ç£å¼æ™ºèƒ½ä½“")
st.markdown("- **12 - å›¾/ä¸–ç•Œæ¨¡å‹è®°å¿†**ï¼šä»æ–‡æœ¬æ„å»ºçŸ¥è¯†å›¾è°±ï¼Œæ”¯æŒè‡ªç„¶è¯­è¨€å¤šè·³é—®ç­”ï¼ˆText-to-Cypherï¼‰")
st.markdown("- **13 - å¹¶è¡Œæ¢ç´¢+é›†æˆå†³ç­–**ï¼šå¤šè·¯åˆ†æå¸ˆå¹¶è¡Œåˆ†æï¼ŒCIO ç»¼åˆæŠ•èµ„å»ºè®®ï¼ˆæ‰‡å‡º/æ‰‡å…¥ï¼‰")
st.markdown("- **14 - å¯è§‚æµ‹ä¸è¯•è·‘å¤–å£³**ï¼šæ‹Ÿç¨¿â†’è¯•è·‘é¢„è§ˆâ†’äººå·¥å®¡æ ¸ï¼ˆapprove/rejectï¼‰â†’æ‰§è¡Œæˆ–å–æ¶ˆ")
st.markdown("- **15 - è‡ªæ”¹è¿›å¾ªç¯**ï¼šç”Ÿæˆâ†’è¯„å®¡â†’ä¿®è®¢å¾ªç¯ï¼ˆSelf-Refineï¼‰ï¼Œè´¨é‡è¾¾æ ‡æˆ–è¾¾æœ€å¤§è½®æ•°ç»“æŸ")
st.markdown("- **16 - ç»†èƒè‡ªåŠ¨æœº/ç½‘æ ¼æ™ºèƒ½ä½“**ï¼šç½‘æ ¼è·¯å¾„æ³¢ä¼ æ’­ä¸æ²¿æ¢¯åº¦æ‹£è´§ï¼Œä»“åº“ç‰©æµæ¼”ç¤º")
st.markdown("- **17 - åæ€å¼å…ƒè®¤çŸ¥**ï¼šå…ƒè®¤çŸ¥åˆ†æåè·¯ç”±ï¼šç›´æ¥å›ç­”/ç”¨å·¥å…·/å‡çº§äººå·¥ï¼ˆåŒ»ç–—åˆ†è¯Šï¼‰")

st.markdown("\n### æŠ€æœ¯æ ˆ")
st.markdown("- **LangGraph**ï¼šæ„å»ºæ™ºèƒ½ä½“å·¥ä½œæµ")
st.markdown("- **ModelScope**ï¼šæä¾›è¯­è¨€æ¨¡å‹æ”¯æŒ")
st.markdown("- **Streamlit**ï¼šæ„å»ºäº¤äº’å¼ç•Œé¢")
st.markdown("- **Python**ï¼šä¸»è¦å¼€å‘è¯­è¨€")
st.markdown("- **å‘é‡æ•°æ®åº“**ï¼šç®¡ç†æƒ…æ™¯è®°å¿†")
st.markdown("- **å›¾æ•°æ®åº“**ï¼šç®¡ç†è¯­ä¹‰è®°å¿†")