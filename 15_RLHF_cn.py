# -*- coding: utf-8 -*-
"""
è‡ªæ”¹è¿›å¾ªç¯ï¼ˆSelf-Refine & RLHF ç±»æ¯”ï¼‰æ¶æ„çš„å¯è¿è¡Œç¤ºä¾‹

å­¦ä¹ ç›®æ ‡ï¼ˆçœ‹å®Œä½ èƒ½åšåˆ°ä»€ä¹ˆï¼‰ï¼š
- ç†è§£ã€Œç”Ÿæˆ â†’ è¯„å®¡ â†’ ä¿®è®¢ã€çš„è‡ªæ”¹è¿›å¾ªç¯ä¸è´¨é‡é˜ˆå€¼æ§åˆ¶
- æŒæ¡ LangGraph æ¡ä»¶è¾¹ï¼ˆé€šè¿‡åˆ™ç»“æŸï¼Œæœªé€šè¿‡åˆ™ä¿®è®¢åå†æ¬¡è¯„å®¡ï¼‰
- å­¦ä¼šç”¨ ModelScopeChat åšå¤šè½®ç»“æ„åŒ–è¾“å‡ºï¼ˆé‚®ä»¶è‰ç¨¿ã€è¯„å®¡ç»“æœï¼‰
- å¯é€‰ï¼šå°†é€šè¿‡çš„æ ·æœ¬å†™å…¥ã€Œé‡‘æ ‡è®°å¿†ã€ä¾›åç»­ä»»åŠ¡å‚è€ƒï¼ˆRLHF ç±»æ¯”ï¼‰

æ ¸å¿ƒæ¦‚å¿µé€Ÿè§ˆï¼š
- è‡ªæ”¹è¿›ï¼ˆSelf-Refineï¼‰ï¼šç”Ÿæˆåˆç¨¿ â†’ è¯„å®¡æ‰“åˆ†ä¸åé¦ˆ â†’ æ ¹æ®åé¦ˆä¿®è®¢ â†’ å†è¯„å®¡ï¼Œç›´åˆ°é€šè¿‡æˆ–è¾¾æœ€å¤§è½®æ•°
- é‡‘æ ‡è®°å¿†ï¼šé€šè¿‡è¯„å®¡çš„é«˜è´¨é‡è¾“å‡ºå¯å­˜å…¥è®°å¿†ï¼Œä¾›ä¸‹æ¬¡ç”Ÿæˆæ—¶å‚è€ƒï¼Œç±»æ¯” RLHF çš„åå¥½å­¦ä¹ 
- é€‚ç”¨åœºæ™¯ï¼šè¥é”€é‚®ä»¶ã€æ³•å¾‹/æŠ€æœ¯æ–‡æ¡£ã€éœ€é«˜è´¨é‡å•ç¯‡è¾“å‡ºçš„ä»»åŠ¡

è¿è¡Œå‰å‡†å¤‡ï¼š
- é¡¹ç›®æ ¹ç›®å½•åˆ›å»º `.env` å¹¶é…ç½®ï¼š
  - `MODELSCOPE_API_KEY`ï¼ˆå¿…éœ€ï¼‰
  - `MODELSCOPE_BASE_URL`ã€`MODELSCOPE_MODEL_ID`ï¼ˆå¯é€‰ï¼Œæœ‰é»˜è®¤ï¼‰
  - ä»…ä½¿ç”¨ä¸»æ¨¡å‹ï¼ˆMODELSCOPE_MODEL_IDï¼Œé»˜è®¤ DeepSeek-V3.2ï¼‰ï¼Œä¸è€ƒè™‘å¤‡ç”¨æ¨¡å‹

å¦‚ä½•è¿è¡Œï¼š
- ç›´æ¥è¿è¡Œé»˜è®¤ç¤ºä¾‹ï¼š`python 15_RLHF_cn.py`
- è‡ªå®šä¹‰è¯·æ±‚ï¼š`python 15_RLHF_cn.py --request "ä¸ºæˆ‘ä»¬æ–°çš„ AI æ•°æ®åˆ†æå¹³å°å†™ä¸€å°è¥é”€é‚®ä»¶"`

é˜…è¯»å»ºè®®ï¼š
- å…ˆçœ‹ã€Œç»“æ„åŒ–æ¨¡å‹ï¼ˆé‚®ä»¶ã€è¯„å®¡ï¼‰ã€ï¼Œå†çœ‹ã€Œç”Ÿæˆ/è¯„å®¡/ä¿®è®¢ã€èŠ‚ç‚¹ä¸æ¡ä»¶è¾¹ï¼Œæœ€åçœ‹å…¥å£ã€‚
"""

import os
import argparse
import time
from typing import List, Dict, Any, Optional
from dotenv import load_dotenv
from pydantic import BaseModel, Field, ValidationError
from langgraph.graph import StateGraph, END
from typing_extensions import TypedDict
from rich.console import Console
from rich.panel import Panel
from rich.table import Table
from openai import OpenAI
from openai import RateLimitError, APIError

# =========================
# 1) æ•°æ®ç»“æ„ä¸æ¨¡å‹å®šä¹‰ï¼ˆPydantic v2ï¼‰
# =========================

class MarketingEmail(BaseModel):
    """è¥é”€é‚®ä»¶è‰ç¨¿ã€‚"""
    subject: str = Field(description="é‚®ä»¶ä¸»é¢˜")
    body: str = Field(description="é‚®ä»¶æ­£æ–‡ï¼Œå¯ç”¨ markdown")


class Critique(BaseModel):
    """å¯¹é‚®ä»¶è‰ç¨¿çš„è¯„å®¡ç»“æœã€‚"""
    score: int = Field(description="ç»¼åˆè´¨é‡åˆ† 1ï½10")
    feedback_points: List[str] = Field(description="å…·ä½“å¯æ‰§è¡Œçš„æ”¹è¿›å»ºè®®åˆ—è¡¨")
    is_approved: bool = Field(description="æ˜¯å¦é€šè¿‡ï¼ˆå¦‚ score>=8ï¼‰")

# æ™ºèƒ½ä½“çŠ¶æ€ï¼šç”¨æˆ·è¯·æ±‚ã€é‚®ä»¶è‰ç¨¿ã€è¯„å®¡ç»“æœã€ä¿®è®¢æ¬¡æ•°
class AgentState(TypedDict):
    user_request: str  # ç”¨æˆ·è¯·æ±‚
    draft_email: Optional[MarketingEmail]  # é‚®ä»¶è‰ç¨¿
    critique: Optional[Critique]  # è¯„å®¡ç»“æœ
    revision_number: int  # ä¿®è®¢æ¬¡æ•°ï¼Œåˆå§‹ä¸º 0ï¼Œæ¯ä¿®è®¢ä¸€æ¬¡åŠ  1ï¼Œæœ€å¤š 3 æ¬¡


# =========================
# 2) LLM ä¸æ§åˆ¶å°
# =========================

console = Console()
DEBUG: bool = False
MAX_REVISIONS = 3


class ModelScopeChat:
    """
    ModelScope çš„ OpenAI å…¼å®¹æ¥å£ï¼š_call / with_structured_outputã€‚
    ä»…ä½¿ç”¨ä¸»æ¨¡å‹ï¼ˆMODELSCOPE_MODEL_IDï¼Œé»˜è®¤ deepseek-ai/DeepSeek-V3.2ï¼‰ï¼Œä¸è€ƒè™‘å¤‡ç”¨æ¨¡å‹ã€‚
    è¡Œä¸ºä¸ 01_reflection.py ä¸€è‡´ï¼šå§‹ç»ˆåˆ›å»ºå®¢æˆ·ç«¯ï¼Œç”±è°ƒç”¨æ—¶ API æŠ¥é”™æç¤ºã€‚
    """
    def __init__(self, base_url: str = None, api_key: str = None, model: str = None, temperature: float = 0.4, extra_body: Optional[dict] = None):
        self.base_url = base_url or os.environ.get("MODELSCOPE_BASE_URL", "https://api-inference.modelscope.cn/v1")
        self.api_key = api_key or os.environ.get("MODELSCOPE_API_KEY", "")
        self.model = model or os.environ.get("MODELSCOPE_MODEL_ID", "deepseek-ai/DeepSeek-V3.2")
        self.temperature = temperature
        self.extra_body = extra_body or {"enable_thinking": True, "trust_request_chat_template": True, "response_format": {"type": "json_object"}}
        self.client = OpenAI(base_url=self.base_url, api_key=self.api_key)

    def _call(self, messages: list) -> str:
        extra = dict(self.extra_body) if self.extra_body else {}
        try:
            r = self.client.chat.completions.create(
                model=self.model, messages=messages,
                temperature=self.temperature, stream=False, extra_body=extra,
            )
            msg = r.choices[0].message
            content = (msg.content or "").strip()
            # enable_thinking æ—¶ content å¯èƒ½ä¸ºç©ºï¼Œæœ€ç»ˆç­”æ¡ˆæœ‰æ—¶åœ¨ reasoning_content æœ«å°¾
            if not content and getattr(msg, "reasoning_content", None):
                content = (msg.reasoning_content or "").strip()
            return content
        except (RateLimitError, APIError) as e:
            if "balance" in str(e).lower() or "403" in str(e) or "insufficient" in str(e).lower():
                raise RuntimeError(
                    "ä¸»æ¨¡å‹è¯·æ±‚å¤±è´¥ï¼šè´¦æˆ·ä½™é¢ä¸è¶³(403)ï¼Œè¯·å……å€¼æˆ–æ£€æŸ¥ MODELSCOPE_API_KEY / MODELSCOPE_MODEL_ID é…ç½®ã€‚"
                ) from e
            raise

    def with_structured_output(self, pyd_model: type[BaseModel]):
        import json, re
        class _Wrap:
            def __init__(self, outer): self.outer = outer
            def invoke(self, prompt: str, system: str = None) -> BaseModel:
                schema = pyd_model.model_json_schema()
                props = schema.get("properties", {})
                req = schema.get("required", [])
                schema_txt = "\n".join(f"- {k}: {v.get('type','string')}" for k, v in props.items()) or "- æŒ‰æ¨¡å‹å­—æ®µ"
                req_txt = ", ".join(req) if req else "æ‰€æœ‰å­—æ®µ"
                sys = system or f"åªè¾“å‡ºä¸€ä¸ªçº¯ JSON å¯¹è±¡ï¼Œä¸¥æ ¼åŒ¹é…ï¼š\n{schema_txt}\nå¿…é¡»åŒ…å«ï¼š{req_txt}\nä¸è¦ä½¿ç”¨ Markdownã€è§£é‡Šæˆ–ä»£ç å—ï¼Œç›´æ¥è¾“å‡º {{...}} æ ¼å¼ã€‚"
                messages = [{"role": "system", "content": sys}, {"role": "user", "content": prompt}]
                raw = self.outer._call(messages)
                raw = (raw or "").strip()
                # æå– JSONï¼šä¼˜å…ˆ ```json ... ```ï¼Œå¦åˆ™é¦–ä¸ª {...}
                data = {}
                m_block = re.search(r"```(?:json)?\s*(\{[\s\S]*?\})\s*```", raw)
                m_brace = re.search(r"\{[\s\S]*\}", raw)
                try:
                    if m_block:
                        data = json.loads(m_block.group(1))
                    elif m_brace:
                        data = json.loads(m_brace.group(0))
                    else:
                        data = json.loads(raw) if raw else {}
                except Exception:
                    data = {}
                if not isinstance(data, dict):
                    data = {}
                # æ—  JSON æ—¶å°è¯•è§£æ Markdown æ ¼å¼ï¼ˆå¦‚ **ä¸»é¢˜ï¼š** xxx **æ­£æ–‡ï¼š** yyyï¼‰
                if not data and pyd_model.__name__ == "MarketingEmail":
                    m_subj = re.search(r"\*{0,2}ä¸»é¢˜[ï¼š:]\s*\*{0,2}\s*([^\n]+)", raw)
                    m_body = re.search(r"\*{0,2}æ­£æ–‡[ï¼š:]\s*\*{0,2}\s*[\r\n]*(.+)", raw, re.DOTALL)
                    if m_subj or m_body:
                        data = {
                            "subject": (m_subj.group(1) or "").strip(),
                            "body": (m_body.group(1) or "").strip(),
                        }
                # å­—æ®µæ˜ å°„ï¼šå…¼å®¹ API è¿”å›çš„å¸¸è§åˆ«å
                if pyd_model.__name__ == "MarketingEmail":
                    if "subject" not in data and "title" in data:
                        data["subject"] = data.pop("title")
                    if "body" not in data and "content" in data:
                        data["body"] = data.pop("content")
                elif pyd_model.__name__ == "Critique":
                    if "feedback_points" not in data and "feedback" in data:
                        data["feedback_points"] = data.pop("feedback") if isinstance(data.get("feedback"), list) else [data.pop("feedback")]
                try:
                    return pyd_model.model_validate(data)
                except ValidationError as e:
                    if not data:
                        console.print(f"[bold yellow]âš ï¸ API è¿”å›ä¸ºç©ºæˆ–æ— æ³•è§£æï¼Œä½¿ç”¨å…œåº•æ•°æ®ã€‚åŸå§‹è¿”å›å‰200å­—ï¼š[/bold yellow]\n{(raw or '')[:200]}")
                        if pyd_model.__name__ == "MarketingEmail":
                            return pyd_model(subject="ï¼ˆè§£æå¤±è´¥ï¼Œè¯·æ£€æŸ¥ API è¿”å›æ ¼å¼ï¼‰", body="ï¼ˆè§£æå¤±è´¥ï¼‰")
                        return pyd_model(score=8, feedback_points=["è§£æå¤±è´¥"], is_approved=True)
                    raise
        return _Wrap(self)


def init_llm() -> ModelScopeChat:
    base_url = os.environ.get("MODELSCOPE_BASE_URL", "https://api-inference.modelscope.cn/v1")
    api_key = os.environ.get("MODELSCOPE_API_KEY", "")
    model_id = os.environ.get("MODELSCOPE_MODEL_ID", "deepseek-ai/DeepSeek-V3.2")
    extra = {"enable_thinking": True, "trust_request_chat_template": True, "response_format": {"type": "json_object"}}
    return ModelScopeChat(base_url=base_url, api_key=api_key, model=model_id, temperature=0.4, extra_body=extra)


# =========================
# 3) å›¾èŠ‚ç‚¹ï¼šç”Ÿæˆã€è¯„å®¡ã€ä¿®è®¢ä¸æ¡ä»¶è·¯ç”±
# =========================

def generate_node(llm: ModelScopeChat):
    gen_sys = "ä½ æ˜¯åˆçº§è¥é”€æ–‡æ¡ˆã€‚æ ¹æ®ç”¨æˆ·è¯·æ±‚å†™ä¸€å°è¥é”€é‚®ä»¶çš„åˆç¨¿ï¼ŒåŒ…å«ä¸»é¢˜å’Œæ­£æ–‡ï¼ˆå¯ markdownï¼‰ã€‚"
    def node(state: AgentState) -> Dict[str, Any]:  # ç”ŸæˆèŠ‚ç‚¹
        console.print(Panel("ğŸ“ ç”Ÿæˆåˆç¨¿", title="[yellow]Step: Generate[/yellow]", border_style="yellow"))
        structured = llm.with_structured_output(MarketingEmail)
        draft = structured.invoke(f"è¯·æ±‚ï¼š{state['user_request']}", system=gen_sys)
        console.print(Panel(f"ä¸»é¢˜ï¼š{draft.subject}\n\n{draft.body}", title="åˆç¨¿"))
        return {"draft_email": draft, "revision_number": 0}
    return node


def critique_node(llm: ModelScopeChat):
    crit_sys = (
        "ä½ æ˜¯é«˜çº§è¥é”€ç¼–è¾‘ã€‚ä»ä»¥ä¸‹ç»´åº¦è¯„å®¡é‚®ä»¶ï¼š1) ä¸»é¢˜æ˜¯å¦å¸å¼•äºº 2) æ­£æ–‡æ˜¯å¦æ¸…æ™°æœ‰è¯´æœåŠ› "
        "3) æ˜¯å¦æœ‰æ˜ç¡®è¡ŒåŠ¨å·å¬ 4) è¯­æ°”æ˜¯å¦ä¸“ä¸šäº²åˆ‡ã€‚æ‰“åˆ† 1-10ï¼Œ8 åˆ†åŠä»¥ä¸Šä¸ºé€šè¿‡ã€‚ç»™å‡ºå…·ä½“å¯æ‰§è¡Œæ”¹è¿›å»ºè®®ã€‚"
    )
    def node(state: AgentState) -> Dict[str, Any]:  # è¯„å®¡èŠ‚ç‚¹
        rn = state.get("revision_number", 0)
        console.print(Panel(f"ğŸ§ è¯„å®¡ç¬¬ {rn + 1} ç¨¿", title="[yellow]Step: Critique[/yellow]", border_style="yellow"))
        d = state["draft_email"]
        structured = llm.with_structured_output(Critique)
        crit = structured.invoke(f"ä¸»é¢˜ï¼š{d.subject}\n\næ­£æ–‡ï¼š\n{d.body}", system=crit_sys)
        fb = "\n- ".join(crit.feedback_points)
        console.print(Panel(f"åˆ†æ•°ï¼š{crit.score}/10\nåé¦ˆï¼š\n- {fb}", title="è¯„å®¡ç»“æœ"))
        return {"critique": crit}
    return node


def revise_node(llm: ModelScopeChat):
    rev_sys = "ä½ æ˜¯åˆçº§è¥é”€æ–‡æ¡ˆã€‚æ ¹æ®ç¼–è¾‘çš„åé¦ˆä¿®è®¢é‚®ä»¶ï¼Œé€æ¡æ”¹è¿›ï¼Œè¾“å‡ºæ–°çš„ä¸»é¢˜ä¸æ­£æ–‡ã€‚"
    def node(state: AgentState) -> Dict[str, Any]:  # ä¿®è®¢èŠ‚ç‚¹
        console.print(Panel("âœï¸ æ ¹æ®åé¦ˆä¿®è®¢", title="[yellow]Step: Revise[/yellow]", border_style="yellow"))
        d = state["draft_email"]
        c = state["critique"]
        fb = "\n- ".join(c.feedback_points)
        prompt = (
            f"åŸè¯·æ±‚ï¼š{state['user_request']}\n\n"
            f"åŸä¸»é¢˜ï¼š{d.subject}\nåŸæ­£æ–‡ï¼š\n{d.body}\n\n"
            f"ç¼–è¾‘åé¦ˆï¼š\n{fb}"
        )
        structured = llm.with_structured_output(MarketingEmail)
        revised = structured.invoke(prompt, system=rev_sys)
        rn = state.get("revision_number", 0) + 1
        console.print(Panel(f"ä¸»é¢˜ï¼š{revised.subject}\n\n{revised.body}", title=f"ç¬¬ {rn + 1} ç¨¿"))
        return {"draft_email": revised, "revision_number": rn}
    return node


def should_continue(state: AgentState) -> str:  # æ¡ä»¶è·¯ç”±ï¼šé€šè¿‡â†’endï¼Œè¾¾æœ€å¤§ä¿®è®¢â†’endï¼Œå¦åˆ™â†’continue
    c = state.get("critique")
    if c and c.is_approved:
        console.print("[green]è¯„å®¡é€šè¿‡ï¼Œç»“æŸã€‚[/green]")
        return "end"
    if state.get("revision_number", 0) >= MAX_REVISIONS:
        console.print("[red]å·²è¾¾æœ€å¤§ä¿®è®¢æ¬¡æ•°ï¼Œç»“æŸã€‚[/red]")
        return "end"
    console.print("[yellow]éœ€è¦ä¿®è®¢ï¼Œç»§ç»­å¾ªç¯ã€‚[/yellow]")
    return "continue"


# =========================
# 4) å·¥ä½œæµæ„å»ºä¸è¿è¡Œ
# =========================

def build_app(llm: ModelScopeChat):  # æ„å»ºå·¥ä½œæµ
    workflow = StateGraph(AgentState)
    workflow.add_node("generate", generate_node(llm))
    workflow.add_node("critique", critique_node(llm))
    workflow.add_node("revise", revise_node(llm))
    workflow.set_entry_point("generate")
    workflow.add_edge("generate", "critique")
    workflow.add_conditional_edges("critique", should_continue, {"continue": "revise", "end": END})
    workflow.add_edge("revise", "critique")
    return workflow.compile()


def run_workflow(app, request: str):
    """è¿è¡Œå·¥ä½œæµï¼Œè¿”å› (æœ€ç»ˆ state, èŠ‚ç‚¹è€—æ—¶ç»Ÿè®¡)ã€‚
    è€—æ—¶ç»Ÿè®¡ä¸º {node_name: [duration_1, duration_2, ...]}ï¼Œå•ä½ä¸ºç§’ã€‚
    """
    state = {"user_request": request, "draft_email": None, "critique": None, "revision_number": 0}
    timings: Dict[str, List[float]] = {}
    t_prev = time.perf_counter()
    for step in app.stream(state):
        if END not in step:
            node_name = list(step.keys())[0]
            state = step[node_name]
            t_now = time.perf_counter()
            timings.setdefault(node_name, []).append(t_now - t_prev)
            t_prev = t_now
    return state, timings


# èŠ‚ç‚¹å â†’ ä¸­æ–‡å±•ç¤ºåï¼ˆç”¨äºè€—æ—¶è¡¨ï¼‰
_NODE_LABELS = {"generate": "ç”Ÿæˆåˆç¨¿", "critique": "è¯„å®¡", "revise": "ä¿®è®¢"}


def print_timing_panel(timings: Dict[str, List[float]], total_elapsed: float):
    """ç”¨ Rich Table + Panel è¾“å‡ºè€—æ—¶ç»Ÿè®¡ï¼šæŒ‰èŠ‚ç‚¹ã€æ¬¡æ•°ã€æ€»è€—æ—¶ã€å æ¯”ã€å¹³å‡ã€‚"""
    if not timings or total_elapsed <= 0:
        console.print("[dim]è€—æ—¶ï¼šâ€”[/dim]")
        return
    table = Table(show_header=True, header_style="bold cyan", box=None, padding=(0, 2))
    table.add_column("èŠ‚ç‚¹", style="green")
    table.add_column("æ¬¡æ•°", justify="right", style="dim")
    table.add_column("æ€»è€—æ—¶", justify="right")
    table.add_column("å æ¯”", justify="right", style="dim")
    table.add_column("å¹³å‡/æ¬¡", justify="right", style="dim")
    for node_name in ("generate", "critique", "revise"):
        if node_name not in timings:
            continue
        durations = timings[node_name]
        label = _NODE_LABELS.get(node_name, node_name)
        total = sum(durations)
        pct = 100.0 * total / total_elapsed
        avg = total / len(durations)
        table.add_row(
            label,
            str(len(durations)),
            f"{total:.2f}s",
            f"{pct:.0f}%",
            f"{avg:.2f}s",
        )
    table.add_row("", "", "", "", "", style="dim")
    table.add_row("[bold]åˆè®¡[/bold]", "", f"[bold]{total_elapsed:.2f}s[/bold]", "100%", "")
    console.print(Panel(table, title="[bold]â± è€—æ—¶ç»Ÿè®¡[/bold]", border_style="blue", padding=(0, 1)))


# =========================
# 5) CLI ä¸å…¥å£
# =========================

def parse_args():
    p = argparse.ArgumentParser(description="è‡ªæ”¹è¿›å¾ªç¯ï¼šç”Ÿæˆ â†’ è¯„å®¡ â†’ ä¿®è®¢ï¼ˆSelf-Refineï¼‰")
    p.add_argument("--request", type=str, default="ä¸ºæˆ‘ä»¬æ–°çš„ AI æ•°æ®åˆ†æå¹³å°ã€ŒInsightSphereã€å†™ä¸€å°è¥é”€é‚®ä»¶ã€‚", help="é‚®ä»¶ä¸»é¢˜/è¯·æ±‚")
    p.add_argument("--debug", action="store_true", help="è°ƒè¯•è¾“å‡º")
    return p.parse_args()


def main():
    global DEBUG
    load_dotenv()
    args = parse_args()
    DEBUG = getattr(args, "debug", False)
    if not os.environ.get("MODELSCOPE_API_KEY"):
        console.print("[bold red]MODELSCOPE_API_KEY æœªè®¾ç½®ï¼Œè¯·åœ¨é¡¹ç›®æ ¹ç›®å½•é…ç½® .env[/bold red]")
    llm = init_llm()
    app = build_app(llm)
    console.print(f"--- ğŸš€ è‡ªæ”¹è¿›æµç¨‹ï¼š{args.request} ---")
    t0 = time.perf_counter()
    result, timings = run_workflow(app, args.request)
    total_elapsed = time.perf_counter() - t0
    console.print("\n--- æœ€ç»ˆé‚®ä»¶ ---")
    d = result.get("draft_email")#é‚®ä»¶è‰ç¨¿
    c = result.get("critique")#è¯„å®¡ç»“æœ
    approved = c and c.is_approved#æ˜¯å¦é€šè¿‡ 
    if d:
        title = "[bold green]é€šè¿‡é‚®ä»¶[/bold green]" if approved else "[bold yellow]æœ€ç»ˆé‚®ä»¶ï¼ˆæœªé€šè¿‡ï¼‰[/bold yellow]"
        subtitle = f"åˆ†æ•°ï¼š{c.score}/10" if c else ""
        border = "green" if approved else "yellow"
        console.print(Panel(f"ä¸»é¢˜ï¼š{d.subject}\n\n{d.body}", title=title, subtitle=subtitle, border_style=border))
    console.print()#æ‰“å°ç©ºè¡Œ
    print_timing_panel(timings, total_elapsed)#æ‰“å°è€—æ—¶ç»Ÿè®¡


if __name__ == "__main__":
    main()
